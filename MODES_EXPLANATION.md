# Diferencias entre LOCAL y CLOUD

## ‚úÖ LO QUE ES IGUAL EN AMBOS MODOS

**Ambos modos usan OpenRouter para LLM**:
- Chat queries ‚Üí OpenRouterLLMProvider
- Query understanding ‚Üí OpenRouter
- Reranking ‚Üí OpenRouter
- Generation ‚Üí OpenRouter
- Verification ‚Üí OpenRouter

## üîÄ LO QUE CAMBIA ENTRE MODOS

### Modo LOCAL
- **Embeddings**: `LocalEmbeddingProvider`
  - Prioridad 1: sentence-transformers (all-MiniLM-L6-v2) - 384 dims
  - Prioridad 2: OpenRouter API (nomic-embed) - 768 dims
  - Prioridad 3: Hash fallback - 384 dims
- **Storage**: ChromaDB (`SimpleVectorStore`)
  - Archivo local: `./chroma_db`
- **PDF Storage**: Sistema de archivos local

### Modo CLOUD
- **Embeddings**: `OpenRouterEmbeddingProvider`
  - OpenRouter API (nomic-embed-text-v1.5) - 768 dims
- **Storage**: Supabase pgvector (`SupabaseVectorStore`)
  - Tabla: `cv_embeddings`
  - Vector dimension: 768
- **PDF Storage**: Supabase Storage bucket `cv-pdfs`

---

## üìÅ C√≥digo que separa los modos

### `backend/app/providers/factory.py`

```python
# Embeddings - SEPARADOS
def get_embedding_provider(mode):
    if mode == Mode.CLOUD:
        return OpenRouterEmbeddingProvider()  # nomic-embed v√≠a API
    else:
        return LocalEmbeddingProvider()  # sentence-transformers o fallback

# Vector Store - SEPARADOS
def get_vector_store(mode):
    if mode == Mode.CLOUD:
        return SupabaseVectorStore()  # Supabase pgvector
    else:
        return SimpleVectorStore()  # ChromaDB local

# LLM - MISMO PARA AMBOS
def get_llm_provider(mode, model):
    return OpenRouterLLMProvider(model=model)  # Siempre OpenRouter
```

---

## ‚úÖ Estado actual del c√≥digo

Los modos NO est√°n mezclados:

1. **LOCAL mode** usa:
   - ‚úÖ LocalEmbeddingProvider (l√≠nea 20-21 factory.py)
   - ‚úÖ SimpleVectorStore/ChromaDB (l√≠nea 34-35 factory.py)
   - ‚úÖ OpenRouterLLMProvider (l√≠nea 58-59 factory.py)

2. **CLOUD mode** usa:
   - ‚úÖ OpenRouterEmbeddingProvider (l√≠nea 17-18 factory.py)
   - ‚úÖ SupabaseVectorStore (l√≠nea 31-32 factory.py)
   - ‚úÖ OpenRouterLLMProvider (l√≠nea 58-59 factory.py)

---

## üîß Lo que se arregl√≥

**Problema**: `index_documents()` fallaba con "Providers not initialized" en CLOUD mode

**Soluci√≥n**: `from_factory()` ahora inicializa embedder y vector_store inmediatamente:
- Permite subir CVs y crear embeddings en AMBOS modos
- LLM providers se inicializan lazy cuando se hace una query (necesitan el modelo del frontend)

**Archivos modificados**: 
- `backend/app/services/rag_service_v5.py` l√≠neas 737-750

**NO se toc√≥**:
- ‚úÖ factory.py - separaci√≥n de modos intacta
- ‚úÖ local/embeddings.py - embeddings locales intactos
- ‚úÖ local/vector_store.py - ChromaDB intacto
- ‚úÖ cloud/embeddings.py - OpenRouter embeddings intacto
- ‚úÖ cloud/vector_store.py - Supabase intacto
