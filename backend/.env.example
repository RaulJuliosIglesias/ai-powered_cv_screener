# ============================================
# CV Screener - Environment Configuration
# ============================================

# Mode Selection
# Options: local, cloud
DEFAULT_MODE=local

# LangChain Integration (Optional)
# Set to true to use LangChain RAG service instead of RAGServiceV3
USE_LANGCHAIN=false

# ============================================
# LLM PROVIDERS
# ============================================

# OpenRouter API (Required for cloud mode)
# Get your key at: https://openrouter.ai/keys
OPENROUTER_API_KEY=sk-or-v1-xxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Google AI Studio (Optional - for LangChain with Gemini)
# Get your key at: https://aistudio.google.com/apikey
GOOGLE_API_KEY=

# OpenAI (Optional - alternative for embeddings)
OPENAI_API_KEY=

# ============================================
# DATABASE (Supabase pgvector)
# ============================================

# Supabase Project URL
# Format: https://xxxxx.supabase.co
SUPABASE_URL=https://xxxxxxxxxxxxx.supabase.co

# Supabase Service Role Key (NOT anon key!)
# Found in: Project Settings > API > service_role key
SUPABASE_SERVICE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...

# ============================================
# SERVER CONFIGURATION
# ============================================

# API Host and Port
API_HOST=0.0.0.0
API_PORT=8000

# CORS Origins (comma-separated)
CORS_ORIGINS=http://localhost:6001,http://localhost:5173,http://localhost:5174

# ============================================
# FILE LIMITS
# ============================================

# Maximum file size in MB
MAX_FILE_SIZE_MB=10

# Maximum files per upload
MAX_FILES_PER_UPLOAD=50

# ============================================
# RAG CONFIGURATION
# ============================================

# Number of chunks to retrieve
RETRIEVAL_K=20

# Minimum similarity score threshold
RETRIEVAL_SCORE_THRESHOLD=0.2

# ============================================
# LLM CONFIGURATION
# ============================================

# Temperature (0.0 - 1.0)
LLM_TEMPERATURE=0.1

# Maximum output tokens
LLM_MAX_TOKENS=4096

# ============================================
# LOGGING
# ============================================

# Log level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# Log file path
LOG_FILE=app.log
