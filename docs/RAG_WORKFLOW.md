# RAG Workflow Documentation

> **CV Screener AI - Complete RAG Pipeline Reference**
> 
> Version: 6.0 | Last Updated: January 2026

---

## Table of Contents

1. [System Overview](#system-overview)
2. [V6 Architecture: Orchestration System](#v6-architecture-orchestration-system) â† **NEW in v6.0**
3. [Smart CV Chunking](#smart-cv-chunking)
4. [Architecture Diagram](#architecture-diagram)
5. [Pipeline Stages](#pipeline-stages)
6. [Targeted Retrieval](#targeted-retrieval)
7. [V5 Advanced Features](#v5-advanced-features)
8. [Structured Output Processing](#structured-output-processing)
9. [Core Scripts Reference](#core-scripts-reference)
10. [Data Flow](#data-flow)
11. [Configuration](#configuration)
12. [Providers](#providers)
13. [Error Handling](#error-handling)
14. [Caching & Performance](#caching--performance)
15. [Evaluation & Logging](#evaluation--logging)

---

## System Overview

The CV Screener uses a **multi-step RAG (Retrieval-Augmented Generation) pipeline** designed for intelligent CV analysis and candidate screening. The system supports two operation modes:

| Mode | Description |
|------|-------------|
| **LOCAL** | JSON vector store, local embeddings (sentence-transformers) |
| **CLOUD** | Supabase pgvector, nomic-embed-v1.5 embeddings, OpenRouter LLMs |

### Key Features (V6.0 - Current)

- âœ… **Orchestrator â†’ Structures â†’ Modules**: Complete output processing architecture
- âœ… **9 Structures**: SingleCandidate, RiskAssessment, Comparison, Search, Ranking, JobMatch, TeamBuild, Verification, Summary
- âœ… **29 Modules**: Reusable components (Thinking, Analysis, RiskTable, MatchScore, etc.)
- âœ… **Conversational Context**: `conversation_history` propagated through entire pipeline
- âœ… **Query Type Routing**: Intelligent routing based on query classification

### Key Features (V5.x - Foundation)

- âœ… **Multi-Query Retrieval**: Generate query variations for better recall
- âœ… **HyDE (Hypothetical Document Embeddings)**: Improved semantic matching
- âœ… **Reciprocal Rank Fusion (RRF)**: Combine results from multiple queries
- âœ… **Chain-of-Thought Reasoning**: Structured Self-Ask pattern for complex queries
- âœ… **Claim-Level Verification**: Verify individual claims against source context
- âœ… **Smart CV Chunking**: Intelligent extraction of dates, roles, and experience years
- âœ… **Enriched Metadata**: Pre-calculated `current_role`, `total_experience_years`, `seniority_level`
- âœ… **Targeted Retrieval**: Fetch ALL chunks for a specific candidate
- âœ… **Circuit Breaker & Graceful Degradation**: Resilient architecture

---

## V6 Architecture: Orchestration System

> **NEW in v6.0** - Complete Orchestrator â†’ Structures â†’ Modules architecture

### High-Level Flow

```
User Query â†’ RAG Pipeline â†’ LLM Response â†’ ORCHESTRATOR â†’ Frontend
                                               â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼                          â–¼                          â–¼
              query_type=              query_type=                query_type=
              single_candidate         comparison                 job_match
                    â”‚                          â”‚                          â”‚
                    â–¼                          â–¼                          â–¼
           SingleCandidateStructure  ComparisonStructure      JobMatchStructure
                    â”‚                          â”‚                          â”‚
                    â–¼                          â–¼                          â–¼
             [Modules...]              [Modules...]              [Modules...]
```

### 9 Structures Implemented

| Structure | Query Type | Modules Used |
|-----------|------------|--------------|
| SingleCandidateStructure | `single_candidate` | Thinking, Highlights, Career, Skills, Credentials, RiskTable, Conclusion |
| RiskAssessmentStructure | `red_flags` | Thinking, Analysis, RiskTable, Conclusion |
| ComparisonStructure | `comparison` | Thinking, Analysis, TableModule, Conclusion |
| SearchStructure | `search` | Thinking, DirectAnswer, ResultsTable, Analysis, Conclusion |
| RankingStructure | `ranking` | Thinking, RankingCriteria, RankingTable, TopPick, Conclusion |
| JobMatchStructure | `job_match` | Thinking, Requirements, MatchScore, GapAnalysis, Conclusion |
| TeamBuildStructure | `team_build` | Thinking, TeamRequirements, TeamComposition, SkillCoverage, TeamRisk |
| VerificationStructure | `verification` | Thinking, Claim, Evidence, Verdict, Conclusion |
| SummaryStructure | `summary` | Thinking, TalentPool, SkillDistribution, ExperienceDistribution |

### Conversational Context Flow

All Structures receive `conversation_history` for context-aware responses:

```python
# Orchestrator.process()
structure_data = self.job_match_structure.assemble(
    llm_output=cleaned_llm_output,
    chunks=chunks or [],
    query=query,
    conversation_history=conversation_history or []  # â† Propagated
)
```

For complete architecture details, see [ARCHITECTURE_MODULES.md](./ARCHITECTURE_MODULES.md).

---

## Smart CV Chunking

> **NEW in v5.1** - Intelligent document processing that extracts structured data from CVs

### The Problem (v5.0 and before)

The original `ChunkingService` divided CVs by generic sections (experience, education, skills) but:

- âŒ **No date extraction** - Couldn't identify "current role" vs past roles
- âŒ **No experience calculation** - Couldn't sum years across positions
- âŒ **Basic metadata** - Only stored `section_type` and `candidate_name`
- âŒ **Semantic search limitations** - Questions like "what's their current job?" failed

### The Solution: SmartChunkingService

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           CV PDF UPLOAD                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 0: SMART CHUNKING (SmartChunkingService)                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ 1. EXTRACT STRUCTURED DATA:                                              â”‚â”‚
â”‚  â”‚    â€¢ Parse dates: "2020-Present", "2018-2023", "Jan 2019 - Dec 2021"    â”‚â”‚
â”‚  â”‚    â€¢ Identify current position (Present/Actual/Current indicators)       â”‚â”‚
â”‚  â”‚    â€¢ Extract job titles and companies                                    â”‚â”‚
â”‚  â”‚    â€¢ Calculate duration per position                                     â”‚â”‚
â”‚  â”‚                                                                          â”‚â”‚
â”‚  â”‚ 2. CALCULATE TOTALS:                                                     â”‚â”‚
â”‚  â”‚    â€¢ Total years of experience (earliest start â†’ latest end)             â”‚â”‚
â”‚  â”‚    â€¢ Number of positions held                                            â”‚â”‚
â”‚  â”‚    â€¢ Current role and company                                            â”‚â”‚
â”‚  â”‚                                                                          â”‚â”‚
â”‚  â”‚ 3. CREATE ENRICHED CHUNKS:                                               â”‚â”‚
â”‚  â”‚    â€¢ Summary Chunk (pre-calculated profile)                              â”‚â”‚
â”‚  â”‚    â€¢ Position Chunks (one per job, with dates)                           â”‚â”‚
â”‚  â”‚    â€¢ Skills Chunk                                                        â”‚â”‚
â”‚  â”‚    â€¢ Full CV Chunk (for comprehensive queries)                           â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚  Script: smart_chunking_service.py                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
                         [Embedding & Indexing]
```

### Chunk Types Created

| Chunk Type | Purpose | Key Metadata |
|------------|---------|--------------|
| **Summary** | Quick profile lookup | `current_role`, `current_company`, `total_experience_years`, `position_count` |
| **Position** | Individual job details | `job_title`, `company`, `start_year`, `end_year`, `is_current`, `duration_years` |
| **Skills** | Technical competencies | `skill_count` |
| **Full CV** | Comprehensive queries | All metadata + first 4000 chars |

### Enriched Metadata Schema

```python
# Summary Chunk Metadata
{
    "section_type": "summary",
    "candidate_name": "Matteo Rossi",
    "current_role": "Lead Merchandising Strategist",      # â† NEW
    "current_company": "Global Fashion Retail Corp",      # â† NEW
    "total_experience_years": 6.0,                        # â† NEW (calculated)
    "is_summary": True,                                   # â† NEW
    "position_count": 3                                   # â† NEW
}

# Position Chunk Metadata
{
    "section_type": "experience",
    "candidate_name": "Matteo Rossi",
    "job_title": "Lead Merchandising Strategist",         # â† NEW
    "company": "Global Fashion Retail Corp",              # â† NEW
    "start_year": 2023,                                   # â† NEW
    "end_year": None,                                     # â† NEW (None = Present)
    "is_current": True,                                   # â† NEW
    "duration_years": 2.0,                                # â† NEW
    "position_order": 1                                   # â† NEW (1 = most recent)
}
```

### Date Extraction Patterns

The service recognizes multiple date formats:

```python
YEAR_PATTERNS = [
    r'(\d{4})\s*[-â€“â€”]\s*(Present|Presente|Actual|Current|Now)',  # 2020 - Present
    r'(\d{4})\s*[-â€“â€”]\s*(\d{4})',                                 # 2018 - 2023
    r'(?:Jan|Feb|...)\s*(\d{4})\s*[-â€“â€”]\s*(?:Jan|...)\s*(\d{4})', # Jan 2020 - Dec 2023
    r'(?:\d{1,2}/)?(\d{4})\s*[-â€“â€”]\s*(?:\d{1,2}/)?(\d{4})',       # 01/2020 - 12/2023
]

CURRENT_INDICATORS = ['present', 'presente', 'actual', 'current', 'now', 'hoy', 'actualidad']
```

### Experience Calculation

```python
def _calculate_total_experience(positions: List[JobPosition]) -> float:
    """
    Calculate total years from career span.
    
    Method: max(end_years) - min(start_years)
    
    Example:
        Position 1: 2023-Present (2 years)
        Position 2: 2021-2023    (2 years)
        Position 3: 2019-2021    (2 years)
        
        Total = 2025 - 2019 = 6 years
    """
```

### Summary Chunk Content Example

```
===== CANDIDATE PROFILE: Matteo Rossi =====

CURRENT POSITION: Lead Merchandising Strategist
CURRENT COMPANY: Global Fashion Retail Corp
TOTAL YEARS OF EXPERIENCE: 6 years
NUMBER OF POSITIONS HELD: 3

CAREER HISTORY (chronological, most recent first):
  1. Lead Merchandising Strategist at Global Fashion Retail Corp (2023-Present, 2y) [CURRENT]
  2. Inventory Planner at Fashion Dynamics Inc (2021-2023, 2y)
  3. Junior Buyer at Style Co (2019-2021, 2y)

KEY SKILLS: Python, Excel, SAP, Demand Forecasting, Inventory Management
```

---

## Targeted Retrieval

> **NEW in v5.1** - Retrieve ALL chunks for a specific candidate

### The Problem

When a user asks "tell me everything about Matteo Rossi":

- âŒ **Semantic search** only returns chunks semantically similar to the query
- âŒ May miss the most recent job if query doesn't mention specific terms
- âŒ Cannot reliably answer "what's their current role?" or "how many years of experience?"

### The Solution

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  QUERY: "damelo todo sobre Matteo Rossi"                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 1: CANDIDATE NAME EXTRACTION                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ extract_candidate_name_from_query("damelo todo sobre Matteo Rossi")     â”‚â”‚
â”‚  â”‚                                                                          â”‚â”‚
â”‚  â”‚ Patterns recognized:                                                     â”‚â”‚
â”‚  â”‚ â€¢ "damelo todo sobre X" / "tell me about X"                             â”‚â”‚
â”‚  â”‚ â€¢ "informaciÃ³n sobre X" / "profile of X"                                â”‚â”‚
â”‚  â”‚ â€¢ Direct name queries                                                    â”‚â”‚
â”‚  â”‚                                                                          â”‚â”‚
â”‚  â”‚ Result: ctx.target_candidate_name = "Matteo Rossi"                      â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 5: TARGETED RETRIEVAL (instead of semantic search)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ IF ctx.target_candidate_name is set:                                     â”‚â”‚
â”‚  â”‚                                                                          â”‚â”‚
â”‚  â”‚   vector_store.get_all_chunks_by_candidate("Matteo Rossi")              â”‚â”‚
â”‚  â”‚                                                                          â”‚â”‚
â”‚  â”‚   Returns ALL chunks where metadata.candidate_name matches:              â”‚â”‚
â”‚  â”‚   â€¢ Summary chunk (with pre-calculated totals)                           â”‚â”‚
â”‚  â”‚   â€¢ All position chunks (with dates and durations)                       â”‚â”‚
â”‚  â”‚   â€¢ Skills chunk                                                         â”‚â”‚
â”‚  â”‚   â€¢ Full CV chunk                                                        â”‚â”‚
â”‚  â”‚                                                                          â”‚â”‚
â”‚  â”‚   Sorted by priority: summary â†’ experience â†’ skills â†’ full_cv            â”‚â”‚
â”‚  â”‚                                                                          â”‚â”‚
â”‚  â”‚ ELSE:                                                                    â”‚â”‚
â”‚  â”‚   Standard RRF fusion retrieval (semantic search)                        â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 6: SKIP RERANKING (for targeted retrieval)                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ IF retrieval_strategy == "targeted_candidate":                           â”‚â”‚
â”‚  â”‚   Skip reranking - we want ALL chunks, not filtered by relevance         â”‚â”‚
â”‚  â”‚   Reason: "Skills" chunk may not be semantically similar to query        â”‚â”‚
â”‚  â”‚           but we still want to include it for complete profile           â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Vector Store Method

```python
# SimpleVectorStore.get_all_chunks_by_candidate()

def get_all_chunks_by_candidate(
    self, 
    candidate_name: str, 
    cv_ids: Optional[List[str]] = None
) -> List[Dict[str, Any]]:
    """
    Get ALL chunks for a specific candidate.
    
    - Case-insensitive partial match
    - Returns chunks sorted by section priority
    - Used for single-candidate queries
    """
```

### Benefits

| Query Type | Before (v5.0) | After (v5.1) |
|------------|---------------|--------------|
| "What's Matteo's current role?" | âŒ May miss if "current" not in chunk | âœ… Summary chunk has `current_role` |
| "How many years of experience?" | âŒ Cannot calculate | âœ… `total_experience_years` pre-calculated |
| "Tell me everything about X" | âš ï¸ Only semantically similar chunks | âœ… ALL chunks for that candidate |

---

## Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              USER QUERY                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 1: QUERY UNDERSTANDING                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ â€¢ Model: google/gemini-2.0-flash-001 (fast, cheap)                   â”‚  â”‚
â”‚  â”‚ â€¢ Extracts: query_type, requirements, is_cv_related                  â”‚  â”‚
â”‚  â”‚ â€¢ Reformulates query for better retrieval                            â”‚  â”‚
â”‚  â”‚ â€¢ Output: QueryUnderstandingV5 dataclass                             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  Script: query_understanding_service.py                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 2: MULTI-QUERY GENERATION (V5 NEW)                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ â€¢ Generates 3-5 query variations for broader recall                  â”‚  â”‚
â”‚  â”‚ â€¢ Extracts entities (skills, names, companies)                       â”‚  â”‚
â”‚  â”‚ â€¢ HyDE: Generates hypothetical ideal CV excerpt                      â”‚  â”‚
â”‚  â”‚ â€¢ Output: MultiQueryResult (variations, entities, hyde_document)     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  Script: multi_query_service.py                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 3: GUARDRAIL CHECK                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ â€¢ Keyword matching: CV_KEYWORDS set (100+ terms)                     â”‚  â”‚
â”‚  â”‚ â€¢ Pattern matching: OFF_TOPIC_PATTERNS (recipes, weather, etc.)      â”‚  â”‚
â”‚  â”‚ â€¢ Fast, no LLM call required                                         â”‚  â”‚
â”‚  â”‚ â€¢ Output: GuardrailResult (is_allowed, rejection_message)            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  Script: guardrail_service.py                                              â”‚
â”‚                                                                            â”‚
â”‚  âŒ REJECTED â†’ Return early with rejection message                         â”‚
â”‚  âœ… PASSED â†’ Continue to next step                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 4: MULTI-EMBEDDING (V5 NEW)                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ â€¢ LOCAL: sentence-transformers (384 dims) / CLOUD: nomic-embed (768d) â”‚  â”‚
â”‚  â”‚ â€¢ Embeds: original query + variations + HyDE document                â”‚  â”‚
â”‚  â”‚ â€¢ Cache: LRU with TTL (5 min default)                                â”‚  â”‚
â”‚  â”‚ â€¢ Parallel embedding generation                                      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  Script: embedding_service.py                                              â”‚
â”‚  Provider: LocalEmbeddingProvider / OpenRouterEmbeddingProvider            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 5: FUSION RETRIEVAL (V5 NEW)                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ MULTI-QUERY SEARCH:                                                     â”‚â”‚
â”‚  â”‚ â€¢ Search with each embedding (original + variations + HyDE)             â”‚â”‚
â”‚  â”‚ â€¢ k=10 per query variation                                              â”‚â”‚
â”‚  â”‚                                                                         â”‚â”‚
â”‚  â”‚ RECIPROCAL RANK FUSION (RRF):                                           â”‚â”‚
â”‚  â”‚ â€¢ Combines ranked lists from all queries                                â”‚â”‚
â”‚  â”‚ â€¢ Formula: RRF(d) = Î£ 1/(k + rank(d)) where k=60                        â”‚â”‚
â”‚  â”‚ â€¢ Documents found by multiple queries ranked higher                     â”‚â”‚
â”‚  â”‚                                                                         â”‚â”‚
â”‚  â”‚ â€¢ Threshold: 0.25 default (lower for broader recall)                    â”‚â”‚
â”‚  â”‚ â€¢ Timeout: 20 seconds                                                   â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚  Script: vector_store.py + multi_query_service.py (RRF)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 6: RERANKING                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ â€¢ Model: google/gemini-2.0-flash-001                                    â”‚â”‚
â”‚  â”‚ â€¢ Scores each chunk 1-10 for relevance to query                         â”‚â”‚
â”‚  â”‚ â€¢ Combined score: LLM_score * 0.7 + similarity * 0.3                    â”‚â”‚
â”‚  â”‚ â€¢ Returns ALL chunks reordered (not truncated)                          â”‚â”‚
â”‚  â”‚ â€¢ Can be disabled via config                                            â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚  Script: reranking_service.py                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 7: CHAIN-OF-THOUGHT REASONING (V5 NEW)                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ SELF-ASK PATTERN:                                                       â”‚â”‚
â”‚  â”‚ â€¢ Deep query understanding with explicit reasoning                      â”‚â”‚
â”‚  â”‚ â€¢ Comprehensive candidate inventory                                     â”‚â”‚
â”‚  â”‚ â€¢ Systematic evidence gathering per candidate                           â”‚â”‚
â”‚  â”‚ â€¢ Structured comparison and scoring                                     â”‚â”‚
â”‚  â”‚                                                                         â”‚â”‚
â”‚  â”‚ OUTPUT FORMAT:                                                          â”‚â”‚
â”‚  â”‚ â€¢ :::thinking block with detailed analysis                              â”‚â”‚
â”‚  â”‚ â€¢ :::answer block with final response                                   â”‚â”‚
â”‚  â”‚                                                                         â”‚â”‚
â”‚  â”‚ â€¢ Reflection: Can request more context if needed                        â”‚â”‚
â”‚  â”‚ â€¢ Timeout: 120 seconds                                                  â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚  Script: reasoning_service.py                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 8: RESPONSE GENERATION                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ PROMPT CONSTRUCTION (templates.py):                                     â”‚â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚â”‚
â”‚  â”‚ â”‚ SYSTEM_PROMPT (Expert HR analyst persona)                           â”‚ â”‚â”‚
â”‚  â”‚ â”‚    +                                                                â”‚ â”‚â”‚
â”‚  â”‚ â”‚ QUERY_TEMPLATE / COMPARISON_TEMPLATE / RANKING_TEMPLATE             â”‚ â”‚â”‚
â”‚  â”‚ â”‚    +                                                                â”‚ â”‚â”‚
â”‚  â”‚ â”‚ Formatted context (chunks with CV IDs and metadata)                 â”‚ â”‚â”‚
â”‚  â”‚ â”‚    +                                                                â”‚ â”‚â”‚
â”‚  â”‚ â”‚ Reasoning trace (from Step 7)                                       â”‚ â”‚â”‚
â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚â”‚
â”‚  â”‚                                                                         â”‚â”‚
â”‚  â”‚ â€¢ Models: gemini-2.0-flash, gemini-1.5-pro, gpt-4o, claude-3           â”‚â”‚
â”‚  â”‚ â€¢ Temperature: 0.1 (for accuracy)                                       â”‚â”‚
â”‚  â”‚ â€¢ Max tokens: 4096-8192                                                 â”‚â”‚
â”‚  â”‚ â€¢ Timeout: 120 seconds                                                  â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚  Script: llm.py (OpenRouterLLMProvider)                                      â”‚
â”‚  Templates: templates.py (PromptBuilder class)                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 9: CLAIM-LEVEL VERIFICATION (V5 NEW)                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ CLAIM EXTRACTION:                                                       â”‚â”‚
â”‚  â”‚ â€¢ Extract individual factual claims from response                       â”‚â”‚
â”‚  â”‚ â€¢ Each claim is a verifiable statement                                  â”‚â”‚
â”‚  â”‚                                                                         â”‚â”‚
â”‚  â”‚ CLAIM VERIFICATION:                                                     â”‚â”‚
â”‚  â”‚ â€¢ Check each claim against source context chunks                        â”‚â”‚
â”‚  â”‚ â€¢ Classify as: VERIFIED, UNVERIFIED, or CONTRADICTED                    â”‚â”‚
â”‚  â”‚                                                                         â”‚â”‚
â”‚  â”‚ OUTPUT:                                                                 â”‚â”‚
â”‚  â”‚ â€¢ overall_score: ratio of verified claims                               â”‚â”‚
â”‚  â”‚ â€¢ needs_regeneration: true if too many unverified claims                â”‚â”‚
â”‚  â”‚ â€¢ Min verified ratio: 0.7 (configurable)                                â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚  Script: claim_verifier_service.py                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 10: ITERATIVE REFINEMENT (V5 NEW)                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ IF needs_regeneration == true:                                          â”‚â”‚
â”‚  â”‚   â€¢ Regenerate response with feedback about unverified claims           â”‚â”‚
â”‚  â”‚   â€¢ Include list of contradicted claims to avoid                        â”‚â”‚
â”‚  â”‚   â€¢ Max 1 refinement iteration to prevent loops                         â”‚â”‚
â”‚  â”‚                                                                         â”‚â”‚
â”‚  â”‚ ELSE:                                                                   â”‚â”‚
â”‚  â”‚   â€¢ Pass through to final response                                      â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚  Script: rag_service_v5.py (_step_refinement)                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 11: EVALUATION LOGGING                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ â€¢ Logs to: eval_logs/queries_YYYYMMDD.jsonl                             â”‚â”‚
â”‚  â”‚ â€¢ Fields: query, response, sources, metrics, claim_verification         â”‚â”‚
â”‚  â”‚ â€¢ Tracks: verified/unverified/contradicted claims                       â”‚â”‚
â”‚  â”‚ â€¢ Daily stats aggregation                                               â”‚â”‚
â”‚  â”‚ â€¢ Low confidence tracking (threshold: 0.5)                              â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚  Script: eval_service.py                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              RAG RESPONSE V5                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ {                                                                    â”‚  â”‚
â”‚  â”‚   "answer": "Generated response text...",                            â”‚  â”‚
â”‚  â”‚   "sources": [{"cv_id": "cv_xxx", "filename": "John_Doe.pdf"}],      â”‚  â”‚
â”‚  â”‚   "metrics": {"total_ms": 1234, "stages": {...}},                    â”‚  â”‚
â”‚  â”‚   "confidence_score": 0.85,                                          â”‚  â”‚
â”‚  â”‚   "guardrail_passed": true,                                          â”‚  â”‚
â”‚  â”‚   "verification": {                                                  â”‚  â”‚
â”‚  â”‚     "verified_claims": [...],                                        â”‚  â”‚
â”‚  â”‚     "unverified_claims": [...],                                      â”‚  â”‚
â”‚  â”‚     "claim_verification_score": 0.92                                 â”‚  â”‚
â”‚  â”‚   },                                                                 â”‚  â”‚
â”‚  â”‚   "reasoning_trace": "...",                                          â”‚  â”‚
â”‚  â”‚   "mode": "cloud",                                                   â”‚  â”‚
â”‚  â”‚   "request_id": "abc123"                                             â”‚  â”‚
â”‚  â”‚ }                                                                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Pipeline Stages

### Stage Enum Definition (V5)

```python
class PipelineStage(Enum):
    QUERY_UNDERSTANDING = auto()  # Step 1
    MULTI_QUERY = auto()          # Step 2 (V5 NEW)
    GUARDRAIL = auto()            # Step 3
    EMBEDDING = auto()            # Step 4
    SEARCH = auto()               # Step 5 (Fusion Retrieval)
    RERANKING = auto()            # Step 6
    REASONING = auto()            # Step 7 (V5 NEW)
    GENERATION = auto()           # Step 8
    VERIFICATION = auto()         # Step 9 (Legacy)
    CLAIM_VERIFICATION = auto()   # Step 9 (V5 NEW)
    REFINEMENT = auto()           # Step 10 (V5 NEW)
```

### Stage Metrics

Each stage tracks:
- `duration_ms`: Execution time
- `success`: Boolean status
- `error`: Error message if failed
- `metadata`: Stage-specific data (tokens, costs, etc.)

---

## V5 Advanced Features

### Multi-Query Retrieval

Generates multiple query variations to improve recall:

```python
@dataclass
class MultiQueryResult:
    original_query: str
    variations: List[str]      # 3-5 query variations
    hyde_document: str | None  # Hypothetical ideal CV excerpt
    entities: Dict[str, List[str]]  # Extracted entities
```

**Benefits:**
- Catches documents that match different phrasings
- Entities enable hybrid keyword search
- HyDE improves semantic matching for abstract queries

### HyDE (Hypothetical Document Embeddings)

Instead of just embedding the query, generates a hypothetical ideal answer:

```
Query: "Who has Python experience?"

HyDE Document: "Senior Software Engineer with 5+ years of Python 
development experience. Expert in Django, FastAPI, and data science 
libraries including pandas, numpy, and scikit-learn..."
```

The HyDE embedding often matches relevant documents better than the raw query.

### Reciprocal Rank Fusion (RRF)

Combines results from multiple query embeddings:

```python
def reciprocal_rank_fusion(ranked_lists: List[List[str]], k: int = 60):
    """
    RRF Score = Î£ 1/(k + rank(d))
    
    Documents found by multiple queries get higher scores.
    k=60 is the standard smoothing constant.
    """
```

### Chain-of-Thought Reasoning

Structured Self-Ask pattern for complex queries:

```
:::thinking

### STEP 1: DEEP QUERY UNDERSTANDING
- What is the user's main objective?
- What are explicit vs implicit requirements?

### STEP 2: COMPREHENSIVE CANDIDATE INVENTORY
- List all candidates with initial relevance assessment

### STEP 3: DETAILED EVIDENCE GATHERING
- For each relevant candidate, extract specific evidence

### STEP 4: COMPARATIVE ANALYSIS
- Score candidates against criteria
- Identify gaps and strengths

:::

:::answer
[Final structured response based on reasoning]
:::
```

### Claim-Level Verification

Verifies individual claims rather than the whole response:

```python
@dataclass
class ClaimVerificationResult:
    total_claims: int
    verified_claims: List[VerifiedClaim]    # Found in context
    unverified_claims: List[Claim]          # Not found
    contradicted_claims: List[Claim]        # Conflicts with context
    overall_score: float                    # verified / total
    needs_regeneration: bool                # If score < 0.7
```

### Iterative Refinement

If too many claims are unverified:
1. Identifies problematic claims
2. Regenerates response with explicit instructions to avoid those claims
3. Maximum 1 refinement iteration to prevent loops

### Graceful Degradation

Features auto-disable on repeated failures:

```python
from app.utils.error_handling import degradation

# If multi-query times out, disable for this request
if timeout_error:
    degradation.disable_feature('multi_query', 'Timeout')
    # Pipeline continues without multi-query
```

---

## Structured Output Processing

> **ğŸ“š Full documentation**: [STRUCTURED_OUTPUT.md](./STRUCTURED_OUTPUT.md)

The Structured Output system transforms raw LLM responses into consistent, type-safe data structures.

### Pipeline Step: Output Processing

After LLM generation, the response passes through the **OutputOrchestrator**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 11: STRUCTURED OUTPUT PROCESSING (V5 NEW)                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ ORCHESTRATOR FLOW:                                                       â”‚â”‚
â”‚  â”‚ 1. Pre-clean LLM output (remove code blocks, artifacts)                  â”‚â”‚
â”‚  â”‚ 2. Extract components via 5 specialized modules:                         â”‚â”‚
â”‚  â”‚    â€¢ ThinkingModule     â†’ :::thinking::: blocks                          â”‚â”‚
â”‚  â”‚    â€¢ DirectAnswerModule â†’ First 1-3 sentences                            â”‚â”‚
â”‚  â”‚    â€¢ AnalysisModule     â†’ Detailed analysis section                      â”‚â”‚
â”‚  â”‚    â€¢ TableModule        â†’ Candidate table â†’ TableData                    â”‚â”‚
â”‚  â”‚    â€¢ ConclusionModule   â†’ :::conclusion::: blocks                        â”‚â”‚
â”‚  â”‚ 3. Generate fallback analysis if none extracted                          â”‚â”‚
â”‚  â”‚ 4. Format candidate references: [ğŸ“„](cv:cv_xxx) **Name**                 â”‚â”‚
â”‚  â”‚ 5. Assemble components sequentially                                      â”‚â”‚
â”‚  â”‚ 6. Post-clean (deduplicate, fix formatting)                              â”‚â”‚
â”‚  â”‚                                                                          â”‚â”‚
â”‚  â”‚ OUTPUT:                                                                  â”‚â”‚
â”‚  â”‚ â€¢ StructuredOutput (data model with all components)                      â”‚â”‚
â”‚  â”‚ â€¢ formatted_answer (markdown string for rendering)                       â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚  Script: output_processor/orchestrator.py                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Models

```python
@dataclass
class StructuredOutput:
    direct_answer: str              # Concise 1-3 sentence answer
    raw_content: str                # Original LLM output
    thinking: Optional[str]         # Reasoning (collapsible)
    analysis: Optional[str]         # Detailed analysis
    table_data: Optional[TableData] # Candidate comparison table
    conclusion: Optional[str]       # Final recommendations
    cv_references: List[CVReference]
    parsing_warnings: List[str]
    fallback_used: bool

@dataclass
class TableData:
    title: str                      # "Candidate Comparison Table"
    headers: List[str]              # ["Candidate", "Skills", "Match Score"]
    rows: List[TableRow]            # One row per candidate

@dataclass
class TableRow:
    candidate_name: str             # "Sofia Grijalva"
    cv_id: str                      # "cv_sofia_grijalva_abc123"
    columns: Dict[str, str]         # {"Skills": "Python", "Experience": "5 years"}
    match_score: int                # 0-100 (for color coding)
```

### Table Modes: Comparison vs Individual

| Mode | Use Case | Table Structure |
|------|----------|-----------------|
| **Comparison** | "Who has Python?" | Multiple candidates, one row per candidate |
| **Individual** | "Tell me about Sofia" | Single candidate, one row per attribute |

**Comparison Mode Example**:
```
| Candidate | Skills | Match Score |
|-----------|--------|-------------|
| Sofia G.  | Python | 95% ğŸŸ¢      |
| Carlos L. | Flask  | 75% ğŸŸ¡      |
```

**Individual Mode Example**:
```
| Attribute  | Value                      |
|------------|----------------------------|
| Experience | 5 years backend dev        |
| Skills     | Python, Django, AWS        |
| Education  | B.S. Computer Science, MIT |
```

### Match Score Colors

| Score | Color | Meaning |
|-------|-------|---------|
| â‰¥ 90% | ğŸŸ¢ Green | Strong match |
| 70-89% | ğŸŸ¡ Yellow | Partial match |
| < 70% | âšª Gray | Weak match |

### Candidate Reference Format

All candidate mentions are formatted uniformly:

```
[ğŸ“„](cv:cv_xxx) **Candidate Name**
 â”‚      â”‚            â”‚
 â”‚      â”‚            â””â”€â”€ Bold name (NOT clickable)
 â”‚      â””â”€â”€ cv: prefix (required for frontend)
 â””â”€â”€ ğŸ“„ icon (clickable â†’ opens PDF)
```

---

## Core Scripts Reference

### ğŸ“ Orchestration Layer

| Script | Class | Description |
|--------|-------|-------------|
| `rag_service_v5.py` | `RAGServiceV5` | **Main orchestrator (V5)**. Multi-query, reasoning, claim verification, iterative refinement. |
| `factory.py` | `ProviderFactory` | Factory pattern for provider instantiation based on mode. |

### ğŸ“ Pipeline Steps (in order)

| # | Script | Class | Input â†’ Output |
|---|--------|-------|----------------|
| 1 | `query_understanding_service.py` | `QueryUnderstandingService` | `str` â†’ `QueryUnderstandingV5` |
| 2 | `multi_query_service.py` | `MultiQueryService` | `str` â†’ `MultiQueryResult` **(V5 NEW)** |
| 3 | `guardrail_service.py` | `GuardrailService` | `str` â†’ `GuardrailResult` |
| 4 | `embedding_service.py` | `EmbeddingService` | `List[str]` â†’ `Dict[str, List[float]]` |
| 5 | `vector_store.py` | `SupabaseVectorStore` / `SimpleVectorStore` | `List[float]` â†’ `List[SearchResult]` |
| 6 | `reranking_service.py` | `RerankingService` | `List[SearchResult]` â†’ `RerankResult` |
| 7 | `reasoning_service.py` | `ReasoningService` | `query + context` â†’ `ReasoningResult` **(V5 NEW)** |
| 8 | `llm.py` | `OpenRouterLLMProvider` | `prompt: str` â†’ `str` |
| 9 | `claim_verifier_service.py` | `ClaimVerifierService` | `response + context` â†’ `ClaimVerificationResult` **(V5 NEW)** |
| 10 | `hallucination_service.py` | `HallucinationService` | `response + context` â†’ `HallucinationCheckResult` |
| 11 | `eval_service.py` | `EvalService` | Logs query/response to JSONL |

### ğŸ“ Support Layer

| Script | Class | Description |
|--------|-------|-------------|
| `templates.py` | `PromptBuilder` | All prompt templates and builder methods |
| `chunking_service.py` | `ChunkingService` | CV text â†’ semantic sections |
| `pdf_service.py` | `PDFService` | PDF â†’ text extraction |
| `confidence_calculator.py` | `ConfidenceCalculator` | Calculate confidence scores |
| `cost_tracker.py` | `CostTracker` | Track OpenRouter API costs |
| `base.py` | `EmbeddingProvider`, `VectorStoreProvider`, `LLMProvider` | Abstract interfaces |

### ğŸ“ Output Processing (V5)

> **ğŸ“š Complete documentation**: See [STRUCTURED_OUTPUT.md](./STRUCTURED_OUTPUT.md) for detailed structured output documentation including orchestration flow, data models, and module descriptions.

| Script | Class | Description |
|--------|-------|-------------|
| `output_processor/orchestrator.py` | `OutputOrchestrator` | **Main entry point** - Coordinates extraction and assembly |
| `output_processor/processor.py` | `OutputProcessor` | Invokes 5 modules to extract components |
| `output_processor/modules/thinking_module.py` | `ThinkingModule` | Extracts :::thinking::: blocks |
| `output_processor/modules/direct_answer_module.py` | `DirectAnswerModule` | Extracts concise 1-3 sentence answer |
| `output_processor/modules/analysis_module.py` | `AnalysisModule` | Processes analysis + generates fallbacks |
| `output_processor/modules/table_module.py` | `TableModule` | Parses tables â†’ TableData (comparison/individual) |
| `output_processor/modules/conclusion_module.py` | `ConclusionModule` | Extracts :::conclusion::: blocks |
| `models/structured_output.py` | `StructuredOutput`, `TableData`, `TableRow` | Data models for structured output |

---

## Data Flow

### CV Ingestion Flow

```
PDF Upload
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PDF Service   â”‚ â†’ Extract text from PDF
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Chunking Serviceâ”‚ â†’ Split into sections (experience, education, skills...)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Embedding Serviceâ”‚ â†’ Generate vector for each chunk
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Vector Store   â”‚ â†’ Store in Supabase with metadata
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Query Flow

```
User Question: "Who has Python experience?"
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ QueryUnderstanding:                                            â”‚
â”‚   query_type: "search"                                         â”‚
â”‚   requirements: ["Search for Python skill"]                    â”‚
â”‚   reformulated_prompt: "Find candidates with Python..."        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Guardrail: PASSED (contains CV keywords)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Vector Search:                                                 â”‚
â”‚   Strategy: top-k (search query, large session)                â”‚
â”‚   Results: 10 chunks from 5 different CVs                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Reranking:                                                     â”‚
â”‚   Scores: [9.5, 8.2, 7.8, 6.5, ...]                            â”‚
â”‚   Reordered by relevance                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM Generation:                                                â”‚
â”‚   SYSTEM_PROMPT + QUERY_TEMPLATE + formatted chunks            â”‚
â”‚   â†’ "Based on the CVs, the following candidates have Python    â”‚
â”‚      experience: [CV:cv_abc123] John Doe (5 years)..."         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Configuration

### RAGConfigV5 Dataclass

```python
@dataclass
class RAGConfigV5:
    mode: Mode = Mode.LOCAL
    
    # Model configuration
    understanding_model: str | None = None      # Default: gemini-2.0-flash-001
    reranking_model: str | None = None          # Default: gemini-2.0-flash-001
    generation_model: str | None = None         # Default: gemini-2.0-flash
    reasoning_model: str | None = None          # Default: same as generation
    verification_model: str | None = None       # Default: gemini-2.0-flash-001
    
    # V5 Feature flags (NEW)
    multi_query_enabled: bool = True            # Generate query variations
    hyde_enabled: bool = True                   # Hypothetical document embeddings
    reasoning_enabled: bool = True              # Chain-of-Thought reasoning
    reflection_enabled: bool = True             # Self-reflection in reasoning
    claim_verification_enabled: bool = True     # Claim-level verification
    iterative_refinement_enabled: bool = True   # Regenerate if verification fails
    
    # Legacy feature flags
    reranking_enabled: bool = True
    verification_enabled: bool = True
    streaming_enabled: bool = False
    parallel_steps_enabled: bool = True
    
    # Retrieval settings
    default_k: int = 15                         # Increased for multi-query fusion
    default_threshold: float = 0.25             # Lower for broader recall
    max_context_tokens: int = 60000
    multi_query_k: int = 10                     # k per query variation
    
    # Timeouts (seconds)
    embedding_timeout: float = 10.0
    search_timeout: float = 20.0                # Increased for multi-query
    llm_timeout: float = 120.0
    reasoning_timeout: float = 120.0            # For Chain-of-Thought
    total_timeout: float = 240.0                # Increased for multi-step
```

### Environment Variables

```bash
# Required
OPENAI_API_KEY=your_openai_key           # For embeddings
OPENROUTER_API_KEY=your_openrouter_key    # For LLM generation

# Optional (Cloud mode)
SUPABASE_URL=your_supabase_project_url
SUPABASE_KEY=your_supabase_service_key
GOOGLE_API_KEY=...              # For LangChain Gemini

# Feature flags
USE_LANGCHAIN=false             # Use LangChain wrapper
```

---

## Providers

### Provider Interface

```python
class EmbeddingProvider(ABC):
    async def embed_query(self, text: str) -> EmbeddingResult
    async def embed_documents(self, texts: List[str]) -> EmbeddingResult

class VectorStoreProvider(ABC):
    async def search(self, embedding, k, threshold, cv_ids, diversify_by_cv) -> List[SearchResult]
    async def add_embeddings(self, embeddings, metadatas, ids)

class LLMProvider(ABC):
    async def generate(self, prompt: str, system_prompt: str, **kwargs) -> LLMResult
```

### Provider Implementations

| Provider | Mode | Implementation |
|----------|------|----------------|
| `OpenRouterEmbeddingProvider` | Cloud | OpenAI text-embedding-3-small via OpenRouter |
| `LocalEmbeddingProvider` | Local | sentence-transformers (fallback) |
| `SupabaseVectorStore` | Cloud | pgvector in Supabase |
| `SimpleVectorStore` | Local | NumPy cosine similarity |
| `OpenRouterLLMProvider` | Both | OpenRouter API (Gemini, GPT-4, Claude) |

---

## Error Handling

### Error Types

```python
class RAGError(Exception):
    stage: PipelineStage | None
    severity: ErrorSeverity  # WARNING, RECOVERABLE, FATAL
    cause: Exception | None
    recoverable: bool

class GuardrailError(RAGError):      # Query rejected
class RetrievalError(RAGError):      # Search failed
class GenerationError(RAGError):     # LLM failed
```

### Retry Configuration

```python
@dataclass
class RetryConfig:
    max_attempts: int = 3
    base_delay_ms: int = 100
    max_delay_ms: int = 5000
    exponential_base: float = 2.0
    jitter: bool = True
```

### Circuit Breaker

```python
@dataclass
class CircuitBreakerConfig:
    enabled: bool = True
    failure_threshold: int = 5        # Open after 5 failures
    recovery_timeout_seconds: int = 30 # Try recovery after 30s
    half_open_max_calls: int = 3      # Test calls before closing
```

**States:**
- `CLOSED` â†’ Normal operation
- `OPEN` â†’ Failing, rejecting all calls
- `HALF_OPEN` â†’ Testing recovery

---

## Caching & Performance

### LRU Cache

```python
@dataclass
class CacheConfig:
    enabled: bool = True
    ttl_seconds: int = 300      # 5 minutes
    max_entries: int = 1000
    cache_embeddings: bool = True
    cache_responses: bool = True
```

### What Gets Cached

| Item | Cache Key | TTL |
|------|-----------|-----|
| Query embeddings | `emb:{query_text}` | 5 min |
| Full responses | `resp:{query_hash}` | 5 min |

### Performance Metrics

```python
@dataclass
class PipelineMetrics:
    total_ms: float
    stages: list[StageMetrics]
    cache_hit: bool
    retry_count: int
```

---

## Evaluation & Logging

### Query Log Entry

```python
@dataclass
class QueryLogEntry:
    timestamp: str
    session_id: Optional[str]
    query: str
    response: str
    sources: List[Dict[str, Any]]
    metrics: Dict[str, float]
    hallucination_check: Dict[str, Any]
    guardrail_passed: bool
    confidence_score: float
    mode: str
```

### Log Location

```
eval_logs/
â”œâ”€â”€ queries_20260103.jsonl    # Today's queries
â”œâ”€â”€ queries_20260102.jsonl    # Yesterday's queries
â””â”€â”€ ...
```

### Daily Statistics

```python
@dataclass
class DailyStats:
    date: str
    total_queries: int
    avg_confidence: float
    guardrail_rejections: int
    avg_latency_ms: float
    low_confidence_count: int
    unique_sessions: int
```

---

## Prompt Templates

### System Prompt (Persona)

```python
SYSTEM_PROMPT = """You are an expert HR analyst and CV reviewer assistant.
Your job is to analyze CVs and help with candidate screening.

CRITICAL RULES:
1. ONLY use information from the provided CV context
2. NEVER fabricate information not in the CVs
3. Include [CV:cv_id] references for every claim
4. Use Markdown tables when comparing candidates
..."""
```

### Query Templates

| Template | Use Case |
|----------|----------|
| `QUERY_TEMPLATE` | General questions |
| `QUERY_TEMPLATE_CONCISE` | Short answers |
| `QUERY_TEMPLATE_JSON` | Structured JSON output |
| `COMPARISON_TEMPLATE` | Compare multiple candidates |
| `RANKING_TEMPLATE` | Rank candidates by criteria |

### PromptBuilder Class

```python
class PromptBuilder:
    def build_query_prompt(question, chunks, total_cvs, response_format)
    def build_comparison_prompt(criteria, chunks)
    def build_ranking_prompt(role, criteria, chunks, top_n)
```

---

## API Endpoints

### Query Endpoint

```
POST /api/v2/query
{
    "question": "Who has Python experience?",
    "session_id": "session_xxx",
    "k": 10,
    "threshold": 0.3
}

Response:
{
    "answer": "...",
    "sources": [...],
    "metrics": {...},
    "confidence_score": 0.85,
    "guardrail_passed": true
}
```

### Health Check

```
GET /api/health
{
    "status": "ok",
    "mode": "cloud",
    "reranking_enabled": true,
    "verification_enabled": true
}
```

---

## File Structure

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ routes.py              # Main API routes
â”‚   â”‚   â”œâ”€â”€ routes_v2.py           # V2 API with sessions
â”‚   â”‚   â”œâ”€â”€ routes_sessions.py     # Session management
â”‚   â”‚   â””â”€â”€ dependencies.py        # FastAPI dependencies
â”‚   â”‚
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ rag_service_v5.py      # Main RAG orchestrator (V5) â­
â”‚   â”‚   â”œâ”€â”€ query_understanding_service.py
â”‚   â”‚   â”œâ”€â”€ multi_query_service.py # Query variations + HyDE (V5) â­
â”‚   â”‚   â”œâ”€â”€ reasoning_service.py   # Chain-of-Thought (V5) â­
â”‚   â”‚   â”œâ”€â”€ claim_verifier_service.py # Claim verification (V5) â­
â”‚   â”‚   â”œâ”€â”€ guardrail_service.py
â”‚   â”‚   â”œâ”€â”€ embedding_service.py
â”‚   â”‚   â”œâ”€â”€ reranking_service.py
â”‚   â”‚   â”œâ”€â”€ verification_service.py
â”‚   â”‚   â”œâ”€â”€ hallucination_service.py
â”‚   â”‚   â”œâ”€â”€ chunking_service.py
â”‚   â”‚   â”œâ”€â”€ pdf_service.py
â”‚   â”‚   â”œâ”€â”€ confidence_calculator.py
â”‚   â”‚   â”œâ”€â”€ cost_tracker.py
â”‚   â”‚   â”œâ”€â”€ eval_service.py
â”‚   â”‚   â””â”€â”€ output_processor/      # Output processing (V5) â­
â”‚   â”‚       â”œâ”€â”€ orchestrator.py
â”‚   â”‚       â”œâ”€â”€ processor.py
â”‚   â”‚       â”œâ”€â”€ validators.py
â”‚   â”‚       â””â”€â”€ modules/
â”‚   â”‚           â”œâ”€â”€ thinking_module.py
â”‚   â”‚           â”œâ”€â”€ analysis_module.py
â”‚   â”‚           â”œâ”€â”€ table_module.py
â”‚   â”‚           â”œâ”€â”€ conclusion_module.py
â”‚   â”‚           â”œâ”€â”€ direct_answer_module.py
â”‚   â”‚           â”œâ”€â”€ gap_analysis_module.py   # NEW v5.1.1
â”‚   â”‚           â”œâ”€â”€ red_flags_module.py      # NEW v5.1.1
â”‚   â”‚           â””â”€â”€ timeline_module.py       # NEW v5.1.1
â”‚   â”‚
â”‚   â”œâ”€â”€ providers/
â”‚   â”‚   â”œâ”€â”€ base.py                # Abstract interfaces
â”‚   â”‚   â”œâ”€â”€ factory.py             # Provider factory
â”‚   â”‚   â”œâ”€â”€ cloud/
â”‚   â”‚   â”‚   â”œâ”€â”€ embeddings.py
â”‚   â”‚   â”‚   â”œâ”€â”€ llm.py
â”‚   â”‚   â”‚   â”œâ”€â”€ vector_store.py
â”‚   â”‚   â”‚   â””â”€â”€ sessions.py
â”‚   â”‚   â””â”€â”€ local/
â”‚   â”‚       â”œâ”€â”€ embeddings.py
â”‚   â”‚       â”œâ”€â”€ llm.py
â”‚   â”‚       â””â”€â”€ vector_store.py
â”‚   â”‚
â”‚   â”œâ”€â”€ prompts/
â”‚   â”‚   â””â”€â”€ templates.py           # All prompt templates
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ schemas.py             # Pydantic models
â”‚   â”‚   â””â”€â”€ sessions.py            # Session management
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ error_handling.py      # Graceful degradation (V5) â­
â”‚   â”‚   â””â”€â”€ text_utils.py          # Text processing utilities
â”‚   â”‚
â”‚   â”œâ”€â”€ config.py                  # Settings and configuration
â”‚   â””â”€â”€ main.py                    # FastAPI app entry point
â”‚
â”œâ”€â”€ eval_logs/                     # Query logs (JSONL)
â”œâ”€â”€ migrations/                    # SQL migrations
â””â”€â”€ tests/                         # Test suite
```

---

## Version History

| Version | Date | Commit | Changes |
|---------|------|--------|---------|
| **6.0.0** | **Upcoming** | - | HuggingFace NLI verification, Zero-shot classification, RAGAS evaluation framework ([Roadmap](./roadmap/RAG_V6.md)) |
| **5.1.1** | **2026-01-05** | - | **Current**: GapAnalysisModule, RedFlagsModule, TimelineModule, Deep Enriched Metadata (seniority, job-hopping, FAANG detection) |
| 5.1.0 | 2026-01-04 | - | Smart CV Chunking, Enriched Metadata, Targeted Retrieval, Summary Chunks |
| 5.0.0 | 2026-01-03 21:38 | `b63a069` | Multi-Query, HyDE, RRF, Chain-of-Thought Reasoning, Claim Verification, Iterative Refinement, Graceful Degradation |
| 4.0.0 | 2026-01-03 18:33 | `e785e61` | 4-step pipeline with Re-ranking and LLM Verification, circuit breaker, combined confidence scoring |
| 3.0.0 | 2026-01-03 15:02 | `2870a05` | RAGServiceV3 with confidence scoring, guardrails, 2-step LLM with QueryUnderstanding |
| 2.0.0 | 2026-01-02 17:15 | `dea6b07` | OpenRouter unified LLM provider, session-based chat architecture |
| 1.0.0 | 2026-01-02 13:42 | `27ec7d7` | Initial RAG pipeline with dual-mode architecture (local/cloud) |

---

> **Note**: This project was started on **January 2, 2026**. This document reflects the current state of the RAG system (V5). For future improvements, see the [roadmap documentation](./roadmap/).
