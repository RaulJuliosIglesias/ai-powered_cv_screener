# ğŸ¤– AI Literacy

> **Criterion**: Your awareness of the relevant tools, models, and trends in the AI industry.

---

## ğŸ§  Embedding Models: State-of-the-Art Selection

### Cloud Mode: `nomic-ai/nomic-embed-text-v1.5`

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              NOMIC EMBED TEXT v1.5                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Dimensions:      768                                           â”‚
â”‚  Context Length:  8,192 tokens                                  â”‚
â”‚  MTEB Ranking:    Top-tier open-source embedding model          â”‚
â”‚                                                                  â”‚
â”‚  KEY FEATURE: Task-prefixed embeddings                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Documents: "search_document: <text>"                     â”‚    â”‚
â”‚  â”‚ Queries:   "search_query: <text>"                        â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                  â”‚
â”‚  WHY THIS MODEL:                                                â”‚
â”‚  â€¢ 2024 state-of-the-art open embedding model                   â”‚
â”‚  â€¢ Outperforms text-embedding-ada-002 on retrieval benchmarks   â”‚
â”‚  â€¢ More cost-effective than OpenAI embeddings                   â”‚
â”‚  â€¢ Longer context window (8K vs 8K)                             â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Implementation Awareness**:
```python
# Correct use of task prefixes for asymmetric search
def embed_texts(self, texts: List[str]) -> List[List[float]]:
    # Documents get document prefix
    prefixed_texts = [f"search_document: {t}" for t in texts]
    return self._embed(prefixed_texts)

def embed_query(self, query: str) -> List[float]:
    # Queries get query prefix
    prefixed_query = f"search_query: {query}"
    return self._embed([prefixed_query])[0]
```

### Local Mode: `all-MiniLM-L6-v2`

| Attribute | Value |
|-----------|-------|
| **Dimensions** | 384 |
| **Speed** | ~14,000 sentences/sec on CPU |
| **Size** | 80MB |
| **Quality** | Good for its size |
| **Use Case** | Development, offline environments |

**Why This Model**: Industry-standard for local inference â€” small, fast, and good quality. Perfect for development without API costs.

---

## ğŸ”Œ LLM Integration: Model-Agnostic Architecture

### OpenRouter API Integration

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              MODEL-AGNOSTIC LLM ARCHITECTURE                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                    OpenRouter API                        â”‚    â”‚
â”‚  â”‚                   (Single Endpoint)                      â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                           â”‚                                      â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚           â”‚               â”‚               â”‚                     â”‚
â”‚           â–¼               â–¼               â–¼                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚   OpenAI    â”‚  â”‚  Anthropic  â”‚  â”‚   Google    â”‚             â”‚
â”‚  â”‚ â€¢ GPT-4o    â”‚  â”‚ â€¢ Claude 3.5â”‚  â”‚ â€¢ Gemini    â”‚             â”‚
â”‚  â”‚ â€¢ GPT-4     â”‚  â”‚ â€¢ Claude 3  â”‚  â”‚ â€¢ Gemini    â”‚             â”‚
â”‚  â”‚ â€¢ GPT-3.5   â”‚  â”‚ â€¢ Haiku     â”‚  â”‚   Flash     â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚           â”‚               â”‚               â”‚                     â”‚
â”‚           â–¼               â–¼               â–¼                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚    Meta     â”‚  â”‚   Mistral   â”‚  â”‚   Others    â”‚             â”‚
â”‚  â”‚ â€¢ Llama 3.1 â”‚  â”‚ â€¢ Large     â”‚  â”‚ â€¢ Qwen      â”‚             â”‚
â”‚  â”‚   405B/70B  â”‚  â”‚ â€¢ Mixtral   â”‚  â”‚ â€¢ DeepSeek  â”‚             â”‚
â”‚  â”‚   /8B      â”‚  â”‚ â€¢ 7B        â”‚  â”‚ â€¢ Cohere    â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                                                                  â”‚
â”‚  BENEFITS:                                                       â”‚
â”‚  âœ… No vendor lock-in                                           â”‚
â”‚  âœ… Switch models without code changes                          â”‚
â”‚  âœ… Single API key for all providers                            â”‚
â”‚  âœ… New models available immediately                            â”‚
â”‚  âœ… Cost optimization (mix cheap + powerful)                    â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2-Step Model Strategy (Industry Best Practice)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              2-STEP MODEL OPTIMIZATION                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  STEP 1: Query Understanding                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Model: Fast/Cheap                                        â”‚    â”‚
â”‚  â”‚ â€¢ GPT-3.5 Turbo ($0.0005/1K tokens)                     â”‚    â”‚
â”‚  â”‚ â€¢ Gemini Flash ($0.00001/1K tokens)                     â”‚    â”‚
â”‚  â”‚ â€¢ Llama 3.1 8B ($0.0001/1K tokens)                      â”‚    â”‚
â”‚  â”‚                                                          â”‚    â”‚
â”‚  â”‚ Task: Parse intent, extract entities, reformulate query â”‚    â”‚
â”‚  â”‚ Latency: 100-300ms                                       â”‚    â”‚
â”‚  â”‚ Cost: ~$0.0001/query                                     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                           â”‚                                      â”‚
â”‚                           â–¼                                      â”‚
â”‚  STEP 2: Response Generation                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Model: Powerful                                          â”‚    â”‚
â”‚  â”‚ â€¢ GPT-4o ($0.005/1K tokens)                             â”‚    â”‚
â”‚  â”‚ â€¢ Claude 3.5 Sonnet ($0.003/1K tokens)                  â”‚    â”‚
â”‚  â”‚ â€¢ Gemini 1.5 Pro ($0.00125/1K tokens)                   â”‚    â”‚
â”‚  â”‚                                                          â”‚    â”‚
â”‚  â”‚ Task: Generate comprehensive, cited response            â”‚    â”‚
â”‚  â”‚ Latency: 1-5 seconds                                     â”‚    â”‚
â”‚  â”‚ Cost: ~$0.01/query                                       â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                  â”‚
â”‚  TOTAL SAVINGS: ~40% vs using powerful model for both          â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’¾ Vector Database Knowledge

### Understanding Trade-offs

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              VECTOR DATABASE COMPARISON                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Solution          â”‚ Scale      â”‚ Latency â”‚ Setup    â”‚ Cost     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  In-Memory/JSON    â”‚ <10K docs  â”‚ O(n)    â”‚ Zero     â”‚ Free     â”‚
â”‚  ChromaDB          â”‚ <100K docs â”‚ Fast    â”‚ Medium   â”‚ Free     â”‚
â”‚  pgvector          â”‚ Millions   â”‚ Fast    â”‚ Medium   â”‚ Varies   â”‚
â”‚  Pinecone          â”‚ Billions   â”‚ Fast    â”‚ Easy     â”‚ $$       â”‚
â”‚  Weaviate          â”‚ Millions   â”‚ Fast    â”‚ Medium   â”‚ $        â”‚
â”‚                                                                  â”‚
â”‚  OUR IMPLEMENTATION:                                            â”‚
â”‚  â€¢ LOCAL:  SimpleVectorStore (JSON + cosine similarity)         â”‚
â”‚  â€¢ CLOUD:  Supabase pgvector (PostgreSQL + IVFFlat index)      â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### pgvector Implementation Details

**Awareness of Vector Indexing**:
```sql
-- IVFFlat index for approximate nearest neighbor search
-- lists=100 is optimal for ~10K-100K vectors
CREATE INDEX cv_embeddings_embedding_idx 
ON cv_embeddings 
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);
```

**Understanding of Similarity Operators**:
```sql
-- Cosine distance operator in PostgreSQL
-- <=> returns distance (0-2), we convert to similarity (0-1)
SELECT 
    *,
    1 - (embedding <=> query_embedding) as similarity
FROM cv_embeddings
WHERE 1 - (embedding <=> query_embedding) > 0.3
ORDER BY embedding <=> query_embedding
LIMIT 10;
```

---

## ğŸ“š RAG Best Practices from Recent Research

### Advanced Retrieval Techniques

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              RAG TECHNIQUES IMPLEMENTED                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  TECHNIQUE          â”‚ RESEARCH ORIGIN    â”‚ IMPLEMENTATION       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Multi-Query        â”‚ RAG-Fusion (2023)  â”‚ MultiQueryService    â”‚
â”‚  Retrieval          â”‚                    â”‚ generates variations â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  HyDE               â”‚ Gao et al. (2022)  â”‚ Hypothetical Doc     â”‚
â”‚                     â”‚                    â”‚ Embeddings           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Reranking          â”‚ Cross-encoder      â”‚ LLM-based relevance  â”‚
â”‚                     â”‚ research           â”‚ scoring              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Chain-of-Thought   â”‚ Wei et al. (2022)  â”‚ ReasoningService     â”‚
â”‚                     â”‚                    â”‚ structured thinking  â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### RAG Pipeline Stages (Beyond Basic RAG)

```
BASIC RAG (Tutorial-level):
  Query â†’ Embed â†’ Retrieve â†’ Generate

THIS IMPLEMENTATION (Production-level):
  Query â†’ Understand â†’ Multi-Query â†’ Guardrail â†’ Embed â†’ 
  Retrieve â†’ Rerank â†’ Reason â†’ Generate â†’ Verify Claims â†’ 
  Detect Hallucinations â†’ Log Metrics
```

---

## âœï¸ Prompt Engineering Patterns

### Structured Output Formatting

```python
# Forcing reliable LLM output with JSON schemas
QUERY_UNDERSTANDING_PROMPT = """
Analyze this question about CVs/resumes.

Question: {question}

You MUST respond in the following JSON format:
{
  "intent": "ranking|search|comparison|factual|summary",
  "entities": {
    "names": ["extracted names"],
    "skills": ["extracted skills"],
    "companies": ["extracted companies"],
    "education": ["extracted education"]
  },
  "reformulated_query": "optimized search query"
}
"""
```

### Anti-Hallucination Prompting

```python
GENERATION_PROMPT = """
Answer the question based ONLY on the provided CV context.

CRITICAL RULES:
1. ONLY use information from the provided CV chunks
2. If information is not in the context, say "Not found in CVs"
3. Always cite sources using [CV:cv_id] format
4. Never invent or assume information not in context
5. If uncertain, express uncertainty

Context:
{context}

Question: {question}

Provide a comprehensive answer with citations:
"""
```

---

## ğŸ“Š Evaluation & Observability (Evals)

### LLM Evaluation Awareness

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              EVALUATION METRICS TRACKED                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  RETRIEVAL QUALITY                                              â”‚
â”‚  â”œâ”€â”€ Similarity scores distribution                             â”‚
â”‚  â”œâ”€â”€ Number of chunks retrieved                                 â”‚
â”‚  â”œâ”€â”€ Diversity (unique CVs)                                     â”‚
â”‚  â””â”€â”€ Relevance threshold hit rate                               â”‚
â”‚                                                                  â”‚
â”‚  GENERATION QUALITY                                             â”‚
â”‚  â”œâ”€â”€ Response length                                            â”‚
â”‚  â”œâ”€â”€ Citation count                                             â”‚
â”‚  â”œâ”€â”€ Verification pass rate                                     â”‚
â”‚  â””â”€â”€ Confidence score                                           â”‚
â”‚                                                                  â”‚
â”‚  LATENCY BREAKDOWN                                              â”‚
â”‚  â”œâ”€â”€ Embedding time (ms)                                        â”‚
â”‚  â”œâ”€â”€ Search time (ms)                                           â”‚
â”‚  â”œâ”€â”€ Reranking time (ms)                                        â”‚
â”‚  â”œâ”€â”€ LLM generation time (ms)                                   â”‚
â”‚  â””â”€â”€ Total pipeline time (ms)                                   â”‚
â”‚                                                                  â”‚
â”‚  COST TRACKING                                                  â”‚
â”‚  â”œâ”€â”€ Input tokens per stage                                     â”‚
â”‚  â”œâ”€â”€ Output tokens per stage                                    â”‚
â”‚  â””â”€â”€ Estimated cost per query                                   â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Implementation**:
```python
@dataclass
class PipelineMetrics:
    """Metrics collected during RAG pipeline execution."""
    total_ms: float
    stages: Dict[str, StageMetrics]
    cache_hit: bool
    retry_count: int
    tokens_used: TokenUsage
    estimated_cost: float

@dataclass
class StageMetrics:
    """Metrics for a single pipeline stage."""
    name: str
    latency_ms: float
    success: bool
    details: Dict[str, Any]
```

---

## ğŸ›¡ï¸ Production AI Patterns

### Resilience Patterns

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PRODUCTION RESILIENCE PATTERNS                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  RETRY WITH EXPONENTIAL BACKOFF                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ @dataclass                                               â”‚    â”‚
â”‚  â”‚ class RetryConfig:                                       â”‚    â”‚
â”‚  â”‚     max_attempts: int = 3                                â”‚    â”‚
â”‚  â”‚     base_delay_ms: int = 100                            â”‚    â”‚
â”‚  â”‚     max_delay_ms: int = 5000                            â”‚    â”‚
â”‚  â”‚     exponential_base: float = 2.0                       â”‚    â”‚
â”‚  â”‚     jitter: bool = True  # Prevent thundering herd      â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                  â”‚
â”‚  CIRCUIT BREAKER (FULLY IMPLEMENTED & WIRED)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ @dataclass(frozen=True)                                  â”‚    â”‚
â”‚  â”‚ class CircuitBreakerConfig:                              â”‚    â”‚
â”‚  â”‚     enabled: bool = True                                 â”‚    â”‚
â”‚  â”‚     failure_threshold: int = 5                          â”‚    â”‚
â”‚  â”‚     recovery_timeout_seconds: int = 30                  â”‚    â”‚
â”‚  â”‚     half_open_max_calls: int = 3                        â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚  âœ“ Wired to LLM generation (allow_request/record_success/fail) â”‚
â”‚  âœ“ Wired to reasoning step with graceful degradation           â”‚
â”‚  âœ“ State machine: CLOSED â†’ OPEN â†’ HALF_OPEN â†’ CLOSED           â”‚
â”‚                                                                  â”‚
â”‚  TIMEOUT MANAGEMENT                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ EMBEDDING_TIMEOUT = 10.0    # Fast operation            â”‚    â”‚
â”‚  â”‚ SEARCH_TIMEOUT = 20.0       # Database query            â”‚    â”‚
â”‚  â”‚ LLM_TIMEOUT = 120.0         # Can be slow               â”‚    â”‚
â”‚  â”‚ TOTAL_TIMEOUT = 240.0       # Hard limit                â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                  â”‚
â”‚  GRACEFUL DEGRADATION                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ â€¢ Fallback to simpler response on failure               â”‚    â”‚
â”‚  â”‚ â€¢ Embedding fallback cascade                            â”‚    â”‚
â”‚  â”‚ â€¢ Cache previous successful responses                   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                  â”‚
â”‚  3-LEVEL FALLBACK FOR QUERY UNDERSTANDING                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ LEVEL 1: Retry with Exponential Backoff                 â”‚    â”‚
â”‚  â”‚   â€¢ 3 attempts per model                                â”‚    â”‚
â”‚  â”‚   â€¢ Delays: 1.5s â†’ 3s â†’ 4.5s                           â”‚    â”‚
â”‚  â”‚   â€¢ Only for HTTP 429 (rate limiting)                   â”‚    â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚
â”‚  â”‚ LEVEL 2: Free Model Fallback Chain                      â”‚    â”‚
â”‚  â”‚   â€¢ gemini-2.0-flash-exp:free                          â”‚    â”‚
â”‚  â”‚   â€¢ llama-3.3-70b-instruct:free                        â”‚    â”‚
â”‚  â”‚   â€¢ gemma-3-27b-it:free                                â”‚    â”‚
â”‚  â”‚   â€¢ deepseek-r1-0528:free                              â”‚    â”‚
â”‚  â”‚   â€¢ mistral-7b-instruct:free                           â”‚    â”‚
â”‚  â”‚   âœ“ Strict validation: only `:free` suffix allowed     â”‚    â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚
â”‚  â”‚ LEVEL 3: Heuristic Fallback (No LLM)                    â”‚    â”‚
â”‚  â”‚   â€¢ Keyword detection for query_type                    â”‚    â”‚
â”‚  â”‚   â€¢ Pattern matching for is_cv_related                  â”‚    â”‚
â”‚  â”‚   â€¢ Cost: $0.00 - NEVER FAILS                          â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3-Level Fallback System (Query Understanding)

```python
# From query_understanding_service.py
FREE_MODEL_FALLBACK_CHAIN = [
    "google/gemini-2.0-flash-exp:free",
    "meta-llama/llama-3.3-70b-instruct:free",
    "google/gemma-3-27b-it:free",
    "deepseek/deepseek-r1-0528:free",
    "mistralai/mistral-7b-instruct:free",
]

def _get_models_to_try(self) -> List[str]:
    """Get ordered list of models: primary + free fallbacks."""
    models = [self.model]
    for fallback in FREE_MODEL_FALLBACK_CHAIN:
        if fallback != self.model and fallback.endswith(":free"):
            models.append(fallback)
    return models

def _create_heuristic_fallback(self, query: str) -> QueryUnderstanding:
    """Level 3: Pure heuristic fallback - NEVER fails, costs $0."""
    query_lower = query.lower()
    
    # Detect query type by keywords
    if any(kw in query_lower for kw in ['rank', 'order', 'sort', 'best']):
        query_type = 'ranking'
    elif any(kw in query_lower for kw in ['compare', 'versus', 'vs']):
        query_type = 'comparison'
    # ... more patterns
    
    return QueryUnderstanding(
        understood_query=query,
        query_type=query_type,
        is_cv_related=is_cv_related,
        reformulated_prompt=query
    )
```

**Guarantee**: Query Understanding **NEVER fails** - always produces a result with $0 cost fallback.

### Caching Strategy

```python
@dataclass
class CacheConfig:
    """Configuration for caching layer."""
    enabled: bool = True
    ttl_seconds: int = 300
    max_entries: int = 1000
    cache_embeddings: bool = True
    cache_responses: bool = True
```

---

## ğŸ“ˆ AI Industry Trends Awareness (2024-2025)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              AI TRENDS & PROJECT ALIGNMENT                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  TREND                    â”‚ PROJECT ALIGNMENT                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Multi-Modal RAG          â”‚ Architecture supports extension     â”‚
â”‚                           â”‚ to image/table extraction           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Agentic RAG              â”‚ Self-Ask pattern, iterative         â”‚
â”‚                           â”‚ refinement implemented              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Structured Outputs       â”‚ JSON mode, schema validation        â”‚
â”‚                           â”‚ throughout pipeline                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Smaller, Faster Models   â”‚ 2-step pipeline uses fast models   â”‚
â”‚                           â”‚ where appropriate                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Open-Source Models       â”‚ Llama, Mistral, Qwen supported     â”‚
â”‚                           â”‚ via OpenRouter                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Embedding Evolution      â”‚ Uses latest nomic-embed,           â”‚
â”‚                           â”‚ not legacy ada-002                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  RAG Evaluation           â”‚ Built-in eval logging,             â”‚
â”‚                           â”‚ ready for RAGAS integration         â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Hybrid Search            â”‚ Vector + keyword search            â”‚
â”‚                           â”‚ architecture supported              â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ AI Literacy Summary

| Area | Evidence |
|------|----------|
| **Embedding Models** | Correct selection of nomic-embed-v1.5 (cloud) and MiniLM (local) with proper task prefixes |
| **LLM Landscape** | Model-agnostic design supporting all major providers via OpenRouter |
| **Vector Databases** | Understanding of pgvector, indexing strategies, similarity operators |
| **RAG Research** | Multi-query, HyDE, reranking, CoT â€” beyond basic tutorials |
| **Prompt Engineering** | Structured outputs, anti-hallucination, citation formats |
| **Evaluation** | Per-stage metrics, cost tracking, observability hooks |
| **Production Patterns** | Retries, circuit breakers, caching, timeouts |
| **Industry Trends** | Aligned with 2024-2025 direction (agentic, structured, open models) |

---

<div align="center">

**[â† Previous: Creativity & Ingenuity](./04_CREATIVITY_AND_INGENUITY.md)** Â· **[Back to Index](./INDEX.md)** Â· **[Next: Learn & Adapt â†’](./06_LEARN_AND_ADAPT.md)**

</div>
