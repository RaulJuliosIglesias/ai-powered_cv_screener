# Implementation Plan: Conversational Context Integration

## Document Purpose

Complete plan to integrate the conversational context system with the current CV Screener STRUCTURES/MODULES/ORCHESTRATOR architecture.

**Reference Documents:**
- `docs/CONVERSATIONAL_CONTEXT.md` - Original context design
- `docs/NextUpdate/ORCHESTRATION_STRUCTURES_MODULES.md` - New architecture
- `docs/NextUpdate/IMPLEMENTATION_PLAN.md` - General implementation plan

**Version:** 1.0  
**Date:** January 2026  
**Total Estimated Time:** 20-25 hours

---

# PART 1: CURRENT STATE ANALYSIS

## 1.1 Conversational Context System (Implemented)

### ‚úÖ **Base Infrastructure - COMPLETE**

```python
# SessionManager - Local
backend/app/models/sessions.py:201-218
def get_conversation_history(session_id: str, limit: int = 6) -> List[ChatMessage]

# SessionManager - Cloud (Supabase)
backend/app/providers/cloud/sessions.py:299-336
def get_conversation_history(session_id: str, limit: int = 6) -> List[Dict]
```

**Status:** ‚úÖ Implemented and functional
- Retrieves last N messages (default: 6 = 3 turns)
- Works in local and cloud mode
- Returns format: `[{"role": "user|assistant", "content": "..."}]`

### ‚úÖ **Pipeline Integration - COMPLETA**

```python
# PipelineContextV5
backend/app/services/rag_service_v5.py:554
conversation_history: list[dict[str, str]] = field(default_factory=list)

# query_stream() accepts conversation_history
backend/app/services/rag_service_v5.py:899
async def query_stream(
    self,
    question: str,
    conversation_history: list[dict[str, str]] | None = None,
    ...
)
```

**Status:** ‚úÖ Implemented
- Context flows through entire RAG pipeline
- Stored in `PipelineContextV5`

### ‚úÖ **Endpoint Integration - COMPLETA**

```python
# routes_sessions_stream.py:111-120
history = mgr.get_conversation_history(session_id, limit=6)
conversation_history = [
    {"role": msg.role, "content": msg.content}
    for msg in history
]
```

**Status:** ‚úÖ Implemented
- Endpoint automatically retrieves history
- Passes it to `query_stream()`

### ‚úÖ **Prompt Builder Integration - COMPLETA**

```python
# templates.py
def build_query_prompt(..., conversation_history: list = None)
def build_single_candidate_prompt(..., conversation_history: list = None)
```

**Status:** ‚úÖ Implemented
- Both methods accept `conversation_history`
- Format as `## CONVERSATION HISTORY` section in prompt

---

## 1.2 STRUCTURES/MODULES Architecture (New)

### ‚úÖ **Orchestrator - PARTIALLY UPDATED**

```python
# orchestrator.py:95-103
def process(
    self,
    raw_llm_output: str,
    chunks: List[Dict[str, Any]] = None,
    query: str = "",
    query_type: str = "comparison",
    candidate_name: str = None
) -> tuple[StructuredOutput, str]:
```

**Status:** ‚ö†Ô∏è **Does NOT accept `conversation_history`**

### ‚úÖ **Structures - 9 IMPLEMENTED**

```
backend/app/services/output_processor/structures/
‚îú‚îÄ‚îÄ single_candidate_structure.py   ‚úÖ IMPLEMENTED
‚îú‚îÄ‚îÄ risk_assessment_structure.py    ‚úÖ IMPLEMENTED  
‚îú‚îÄ‚îÄ comparison_structure.py         ‚úÖ IMPLEMENTED
‚îú‚îÄ‚îÄ search_structure.py             ‚úÖ IMPLEMENTED
‚îú‚îÄ‚îÄ ranking_structure.py            ‚úÖ IMPLEMENTED
‚îú‚îÄ‚îÄ job_match_structure.py          ‚úÖ IMPLEMENTED
‚îú‚îÄ‚îÄ team_build_structure.py         ‚úÖ IMPLEMENTED
‚îú‚îÄ‚îÄ verification_structure.py       ‚úÖ IMPLEMENTED
‚îî‚îÄ‚îÄ summary_structure.py            ‚úÖ IMPLEMENTED
```

**Status:** ‚ö†Ô∏è **NONE accept `conversation_history`**

```python
# Current signature (example SingleCandidateStructure)
def assemble(
    self,
    llm_output: str,
    chunks: List[Dict],
    candidate_name: str,
    cv_id: str
) -> Dict[str, Any]:
```

---

## 1.3 Identified Problem: Context Disconnection

### üî¥ **Current Flow (INCOMPLETE)**

```
1. Endpoint retrieves conversation_history       ‚úÖ
2. RAG service receives conversation_history     ‚úÖ
3. PromptBuilder uses conversation_history       ‚úÖ
4. LLM generates response with context           ‚úÖ
5. Orchestrator processes response               ‚ùå WITHOUT context
6. Structure assembles output                    ‚ùå WITHOUT context
```

### üî¥ **Use Cases that FAIL**

#### **Case 1: Single Candidate Follow-up**
```
User: "Give me the complete profile of Juan P√©rez"
‚Üí Orchestrator ‚Üí SingleCandidateStructure ‚úÖ
‚Üí Response: [Complete profile]

User: "What red flags does he have?"
‚Üí Orchestrator ‚Üí RiskAssessmentStructure
‚Üí ‚ùå Does NOT know "What red flags does he have?" refers to Juan P√©rez
‚Üí Needs to re-search candidate based only on current query
```

#### **Case 2: Pronominal References**
```
User: "Compare Juan and Mar√≠a"
‚Üí ComparisonStructure ‚úÖ

User: "And for Backend these two?"
‚Üí ‚ùå "these two" doesn't resolve to Juan and Mar√≠a
‚Üí Structure has no context of who they are
```

#### **Case 3: Search Context**
```
User: "Find Frontend developers with React"
‚Üí SearchStructure ‚úÖ

User: "Which one has more experience?"
‚Üí ‚ùå Does NOT know it refers to previous results
‚Üí Structure cannot filter within previous results
```

---

# PART 2: SOLUTION DESIGN

## 2.1 Target Architecture

### **Complete Flow with Integrated Context**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. ENDPOINT (routes_sessions_stream.py)                    ‚îÇ
‚îÇ    ‚Üì Recupera conversation_history del SessionManager      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 2. RAG SERVICE (rag_service_v5.py)                         ‚îÇ
‚îÇ    ‚Üì Almacena en PipelineContextV5                         ‚îÇ
‚îÇ    ‚Üì [NUEVO] ContextResolver resuelve referencias          ‚îÇ
‚îÇ    ‚Üì Pasa contexto al PromptBuilder                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3. PROMPT BUILDER (templates.py)                           ‚îÇ
‚îÇ    ‚Üì Formatea conversation_history en el prompt            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 4. LLM GENERATION                                           ‚îÇ
‚îÇ    ‚Üì Genera respuesta con contexto                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 5. ORCHESTRATOR (orchestrator.py)                          ‚îÇ
‚îÇ    ‚Üì [NUEVO] Recibe conversation_history                   ‚îÇ
‚îÇ    ‚Üì Enruta a Structure apropiada + contexto               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 6. STRUCTURE (single_candidate_structure.py, etc.)         ‚îÇ
‚îÇ    ‚Üì [NUEVO] Recibe conversation_history                   ‚îÇ
‚îÇ    ‚Üì [NUEVO] Puede adaptar comportamiento seg√∫n contexto   ‚îÇ
‚îÇ    ‚Üì Ensambla output context-aware                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 2.2 Componentes Nuevos a Crear

### **Componente 1: ContextResolver**

**Archivo:** `backend/app/services/context_resolver.py`

**Prop√≥sito:** Resolver referencias pronominales y entidades del contexto conversacional

```python
class ContextResolver:
    """
    Resuelve referencias en la query actual usando el contexto conversacional.
    
    Ejemplos:
    - "¬øQu√© red flags tiene?" + contexto con "Juan P√©rez" ‚Üí "¬øQu√© red flags tiene Juan P√©rez?"
    - "estos dos candidatos" + contexto ["Juan", "Mar√≠a"] ‚Üí "Juan P√©rez y Mar√≠a Garc√≠a"
    - "el mejor" + contexto de comparaci√≥n ‚Üí nombre del candidato mencionado como mejor
    """
    
    def resolve_references(
        self,
        current_query: str,
        conversation_history: list[dict[str, str]]
    ) -> tuple[str, dict]:
        """
        Returns:
            tuple: (resolved_query, context_metadata)
            
        context_metadata = {
            "referenced_candidates": ["Juan P√©rez", "Mar√≠a Garc√≠a"],
            "last_query_type": "comparison",
            "resolution_confidence": 0.95
        }
        """
```

### **Componente 2: SmartContextManager**

**Archivo:** `backend/app/services/smart_context_manager.py`

**Prop√≥sito:** Gesti√≥n inteligente del tama√±o y relevancia del contexto

```python
class SmartContextManager:
    """
    Gestiona el contexto conversacional de forma inteligente:
    - Selecci√≥n de mensajes relevantes (no siempre los √∫ltimos N)
    - Scoring de relevancia basado en la query actual
    - Optimizaci√≥n de tokens
    """
    
    def get_relevant_context(
        self,
        current_query: str,
        full_history: list[dict],
        max_messages: int = 6,
        max_tokens: int = 2000
    ) -> list[dict]:
        """
        Selecciona mensajes m√°s relevantes para la query actual.
        """
```

---

# PARTE 3: PLAN DE IMPLEMENTACI√ìN POR FASES

## **FASE 1: Core Integration (CR√çTICO) - 6-8 horas**

### Objetivo
Hacer que el `conversation_history` fluya desde RAG ‚Üí Orchestrator ‚Üí Structures

### Tareas

#### ‚úÖ **Tarea 1.1: Actualizar Orchestrator**
**Archivo:** `backend/app/services/output_processor/orchestrator.py`

```python
# CAMBIO EN FIRMA
def process(
    self,
    raw_llm_output: str,
    chunks: List[Dict[str, Any]] = None,
    query: str = "",
    query_type: str = "comparison",
    candidate_name: str = None,
    conversation_history: list[dict[str, str]] = None  # ‚Üê NUEVO
) -> tuple[StructuredOutput, str]:
```

**Estimaci√≥n:** 1 hora

---

#### ‚úÖ **Tarea 1.2: Actualizar TODAS las Structures**

**Archivos a modificar (9 archivos):**
```
structures/single_candidate_structure.py
structures/risk_assessment_structure.py
structures/comparison_structure.py
structures/search_structure.py
structures/ranking_structure.py
structures/job_match_structure.py
structures/team_build_structure.py
structures/verification_structure.py
structures/summary_structure.py
```

**Cambio en cada estructura:**
```python
def assemble(
    self,
    llm_output: str,
    chunks: List[Dict],
    # ... otros par√°metros espec√≠ficos de la estructura ...
    conversation_history: list[dict[str, str]] = None  # ‚Üê NUEVO
) -> Dict[str, Any]:
    # Por ahora, solo recibir el par√°metro
    # En Fase 3 se usar√° para l√≥gica context-aware
```

**Estimaci√≥n:** 2 horas (15-20 min por estructura)

---

#### ‚úÖ **Tarea 1.3: Propagar desde RAG ‚Üí Orchestrator**

**Archivo:** `backend/app/services/rag_service_v5.py`

**Ubicaci√≥n:** L√≠nea ~2215 (donde se llama al orchestrator)

```python
# ANTES
structured_output, formatted_answer = orchestrator.process(
    raw_llm_output=ctx.generated_response or "",
    chunks=ctx.effective_chunks,
    query=ctx.question,
    query_type=query_type,
    candidate_name=candidate_name
)

# DESPU√âS
structured_output, formatted_answer = orchestrator.process(
    raw_llm_output=ctx.generated_response or "",
    chunks=ctx.effective_chunks,
    query=ctx.question,
    query_type=query_type,
    candidate_name=candidate_name,
    conversation_history=ctx.conversation_history  # ‚Üê NUEVO
)
```

**Estimaci√≥n:** 30 minutos

---

#### ‚úÖ **Tarea 1.4: Propagar desde Orchestrator ‚Üí Structures**

**Archivo:** `backend/app/services/output_processor/orchestrator.py`

**Ubicaci√≥n:** Cada llamada a `structure.assemble()`

```python
# Ejemplo: SingleCandidateStructure
structure_data = self.single_candidate_structure.assemble(
    llm_output=cleaned_llm_output,
    chunks=chunks or [],
    candidate_name=candidate_name,
    cv_id=cv_id,
    conversation_history=conversation_history  # ‚Üê NUEVO
)

# Repetir para las 9 estructuras
```

**Estimaci√≥n:** 2 horas

---

#### ‚úÖ **Tarea 1.5: Testing Fase 1**

**Tests a realizar:**
1. Query simple sin contexto ‚Üí debe funcionar igual que antes
2. Query con contexto ‚Üí contexto debe fluir pero no afectar output a√∫n
3. Verificar logs muestran que contexto llega a structures

**Estimaci√≥n:** 1.5 horas

---

### **Entregables Fase 1**
- [ ] Orchestrator.process() acepta conversation_history
- [ ] Todas las 9 Structures aceptan conversation_history
- [ ] RAG ‚Üí Orchestrator propagaci√≥n implementada
- [ ] Orchestrator ‚Üí Structures propagaci√≥n implementada
- [ ] Tests b√°sicos pasando
- [ ] Log traces muestran flujo completo del contexto

---

## **FASE 2: Context Resolution (ALTO IMPACTO) - 8-10 horas**

### Objetivo
Resolver referencias pronominales y entidades del contexto antes de procesamiento

### Tareas

#### ‚úÖ **Tarea 2.1: Crear ContextResolver**

**Archivo nuevo:** `backend/app/services/context_resolver.py`

```python
class ContextResolver:
    """Resuelve referencias en queries usando contexto conversacional."""
    
    def __init__(self):
        self.entity_patterns = self._build_entity_patterns()
        self.reference_patterns = self._build_reference_patterns()
    
    def resolve_references(
        self,
        current_query: str,
        conversation_history: list[dict[str, str]]
    ) -> ResolvedQuery:
        """
        Resuelve referencias pronominales y entidades.
        
        Returns:
            ResolvedQuery con:
            - resolved_text: Query expandida
            - referenced_entities: Lista de entidades detectadas
            - confidence: Score de confianza de la resoluci√≥n
            - original_text: Query original sin modificar
        """
```

**Implementaci√≥n detallada:**

1. **Extracci√≥n de entidades del contexto**
   - Nombres de candidatos mencionados
   - CVs espec√≠ficos referenciados
   - Criterios de b√∫squeda previos
   
2. **Detecci√≥n de referencias en query actual**
   - Pronombres: "√©l", "ella", "este candidato", "estos dos"
   - Referencias impl√≠citas: "qu√© red flags tiene" sin nombre
   - Referencias comparativas: "el mejor", "el m√°s senior"

3. **Resoluci√≥n y expansi√≥n**
   - Reemplazar pronombres con entidades
   - Mantener query original si no hay referencias
   - Scoring de confianza

**Estimaci√≥n:** 4-5 horas

---

#### ‚úÖ **Tarea 2.2: Integrar ContextResolver en RAG Pipeline**

**Archivo:** `backend/app/services/rag_service_v5.py`

**Ubicaci√≥n:** Despu√©s de step_understand_query (l√≠nea ~1150)

```python
async def _step_resolve_context(self, ctx: PipelineContextV5):
    """
    NUEVO STEP: Resolver referencias del contexto conversacional.
    
    Debe ejecutarse DESPU√âS de query understanding pero ANTES de retrieval.
    """
    if not ctx.conversation_history:
        ctx.resolved_question = ctx.question
        return
    
    resolver = ContextResolver()
    resolved = resolver.resolve_references(
        current_query=ctx.question,
        conversation_history=ctx.conversation_history
    )
    
    ctx.resolved_question = resolved.resolved_text
    ctx.context_metadata = resolved.metadata
    
    if resolved.resolved_text != ctx.question:
        logger.info(
            f"[CONTEXT] Resolved query: '{ctx.question}' ‚Üí '{resolved.resolved_text}' "
            f"(confidence: {resolved.confidence:.2f})"
        )
```

**Modificar query_stream():**
```python
# Usar resolved_question en lugar de question para el resto del pipeline
# L√≠neas ~1600-2000: Reemplazar ctx.question con ctx.resolved_question
```

**Estimaci√≥n:** 2-3 horas

---

#### ‚úÖ **Tarea 2.3: A√±adir PipelineStage.CONTEXT_RESOLUTION**

**Archivo:** `backend/app/services/rag_service_v5.py`

```python
class PipelineStage(str, Enum):
    # ... existing stages ...
    CONTEXT_RESOLUTION = "context_resolution"  # ‚Üê NUEVO
```

**Emitir evento SSE:**
```python
yield {
    "event": "step",
    "stage": PipelineStage.CONTEXT_RESOLUTION,
    "status": "completed",
    "data": {
        "original_query": ctx.question,
        "resolved_query": ctx.resolved_question,
        "referenced_entities": ctx.context_metadata.get("entities", []),
        "confidence": ctx.context_metadata.get("confidence", 1.0)
    }
}
```

**Estimaci√≥n:** 1 hora

---

#### ‚úÖ **Tarea 2.4: Testing Fase 2**

**Tests espec√≠ficos:**

1. **Test: Referencia simple**
   ```
   Contexto:
   - User: "Dame el perfil de Juan P√©rez"
   - Assistant: "[Perfil completo]"
   
   Query actual: "¬øQu√© red flags tiene?"
   Expected: Resuelto a "¬øQu√© red flags tiene Juan P√©rez?"
   ```

2. **Test: Referencias m√∫ltiples**
   ```
   Contexto:
   - User: "Compara Juan y Mar√≠a"
   - Assistant: "[Comparaci√≥n]"
   
   Query actual: "¬øCu√°l de estos dos es mejor para Backend?"
   Expected: "¬øCu√°l de Juan P√©rez y Mar√≠a Garc√≠a es mejor para Backend?"
   ```

3. **Test: No hay referencias**
   ```
   Query: "Busca desarrolladores Python"
   Expected: Sin cambios
   ```

4. **Test: Confianza baja**
   ```
   Query ambigua sin contexto suficiente
   Expected: confidence < 0.5, usar query original
   ```

**Estimaci√≥n:** 2 horas

---

### **Entregables Fase 2**
- [ ] ContextResolver implementado y testeado
- [ ] Integrado en RAG pipeline como nuevo step
- [ ] Referencias pronominales resueltas correctamente
- [ ] SSE events muestran resoluci√≥n de contexto
- [ ] Test suite con 10+ casos cubriendo escenarios comunes

---

## **FASE 3: Context-Aware Structures (ESPECIALIZACI√ìN) - 5-6 horas**

### Objetivo
Las Structures usan el contexto para adaptar su comportamiento

### Tareas

#### ‚úÖ **Tarea 3.1: RiskAssessmentStructure Context-Aware**

**Archivo:** `structures/risk_assessment_structure.py`

**Mejoras con contexto:**

```python
def assemble(
    self,
    llm_output: str,
    chunks: List[Dict],
    candidate_name: str,
    cv_id: str,
    conversation_history: list[dict] = None
) -> Dict[str, Any]:
    # NUEVO: Analizar conversaci√≥n previa para entender qu√© preocupaciones
    # tiene el usuario sobre este candidato
    
    if conversation_history:
        concerns = self._extract_user_concerns(conversation_history)
        # Ajustar el enfoque del an√°lisis de riesgos
        # Priorizar factores relacionados con las preocupaciones detectadas
    
    # ... resto del ensamblaje ...

def _extract_user_concerns(self, history: list[dict]) -> list[str]:
    """
    Extrae preocupaciones del usuario del contexto.
    
    Ejemplos:
    - "estabilidad" mencionada ‚Üí priorizar job hopping analysis
    - "experiencia t√©cnica" ‚Üí enfocarse en skill gaps
    - "liderazgo" ‚Üí enfocarse en progression pattern
    """
```

**Estimaci√≥n:** 1.5 horas

---

#### ‚úÖ **Tarea 3.2: ComparisonStructure con Memoria**

**Archivo:** `structures/comparison_structure.py`

**Mejoras con contexto:**

```python
def assemble(
    self,
    llm_output: str,
    chunks: List[Dict],
    conversation_history: list[dict] = None
) -> Dict[str, Any]:
    # NUEVO: Detectar si esta comparaci√≥n es continuaci√≥n de otra
    
    if conversation_history:
        previous_comparisons = self._extract_previous_comparisons(history)
        
        if previous_comparisons:
            # Mantener los mismos criterios de comparaci√≥n
            # O expandir la comparaci√≥n con nuevos candidatos
            criteria = previous_comparisons[-1]["criteria"]
```

**Estimaci√≥n:** 1.5 horas

---

#### ‚úÖ **Tarea 3.3: SearchStructure Context-Aware**

**Archivo:** `structures/search_structure.py`

**Mejoras con contexto:**

```python
def assemble(
    self,
    llm_output: str,
    chunks: List[Dict],
    query: str,
    conversation_history: list[dict] = None
) -> Dict[str, Any]:
    # NUEVO: Detectar si b√∫squeda es refinamiento de b√∫squeda anterior
    
    if conversation_history:
        previous_search = self._extract_last_search(history)
        
        if previous_search and self._is_refinement(query, previous_search):
            # Marcar como "Refined search from previous query"
            # Mostrar qu√© cambi√≥
```

**Estimaci√≥n:** 1.5 horas

---

#### ‚úÖ **Tarea 3.4: Testing Fase 3**

**Tests de comportamiento context-aware:**

1. **RiskAssessment**: Usuario menciona "estabilidad" ‚Üí an√°lisis prioriza job hopping
2. **Comparison**: Comparaci√≥n iterativa mantiene criterios
3. **Search**: Refinamiento de b√∫squeda detectado correctamente

**Estimaci√≥n:** 1.5 horas

---

### **Entregables Fase 3**
- [ ] RiskAssessmentStructure usa contexto para priorizar an√°lisis
- [ ] ComparisonStructure mantiene criterios entre comparaciones
- [ ] SearchStructure detecta refinamientos
- [ ] Comportamiento context-aware documentado
- [ ] Tests verifican adaptaci√≥n seg√∫n contexto

---

## **FASE 4: Smart Context Management (OPTIMIZACI√ìN) - 4-5 horas**

### Objetivo
Optimizar qu√© mensajes del contexto se incluyen bas√°ndose en relevancia

### Tareas

#### ‚úÖ **Tarea 4.1: Crear SmartContextManager**

**Archivo nuevo:** `backend/app/services/smart_context_manager.py`

```python
class SmartContextManager:
    """
    Gestiona el contexto conversacional de forma inteligente.
    
    NO siempre usa los √∫ltimos N mensajes - selecciona los m√°s RELEVANTES.
    """
    
    def __init__(self):
        self.max_context_tokens = 2000
        self.default_message_limit = 6
    
    def get_relevant_context(
        self,
        current_query: str,
        full_history: list[dict],
        max_messages: int = None,
        max_tokens: int = None
    ) -> ContextSelection:
        """
        Selecciona mensajes m√°s relevantes.
        
        Algoritmo:
        1. Calcular relevance score para cada mensaje
        2. Siempre incluir √∫ltimo mensaje (contexto inmediato)
        3. Seleccionar top N por score dentro del l√≠mite de tokens
        
        Returns:
            ContextSelection con:
            - selected_messages: Lista de mensajes seleccionados
            - relevance_scores: Score de cada mensaje
            - total_tokens: Tokens estimados
            - selection_reason: Por qu√© se seleccionaron estos mensajes
        """
    
    def _calculate_relevance_score(
        self,
        current_query: str,
        message: dict
    ) -> float:
        """
        Score de relevancia (0.0 - 1.0).
        
        Factores:
        - Overlap de entidades (nombres de candidatos mencionados)
        - Similitud sem√°ntica con query actual
        - Distancia temporal (recency)
        - Tipo de mensaje (user queries score m√°s alto)
        """
```

**Estimaci√≥n:** 2-3 horas

---

#### ‚úÖ **Tarea 4.2: Integrar SmartContextManager**

**Archivo:** `backend/app/api/routes_sessions_stream.py`

```python
# ANTES (l√≠nea ~111)
history = mgr.get_conversation_history(session_id, limit=6)

# DESPU√âS
from app.services.smart_context_manager import SmartContextManager

full_history = mgr.get_conversation_history(session_id, limit=20)  # M√°s mensajes
context_manager = SmartContextManager()

context_selection = context_manager.get_relevant_context(
    current_query=request.message,
    full_history=full_history,
    max_messages=6,
    max_tokens=2000
)

conversation_history = context_selection.selected_messages

logger.info(
    f"[STREAM] Selected {len(conversation_history)} most relevant messages "
    f"(reason: {context_selection.selection_reason})"
)
```

**Estimaci√≥n:** 1 hora

---

#### ‚úÖ **Tarea 4.3: Testing y M√©tricas**

**Tests:**
1. Query sobre candidato mencionado 5 mensajes atr√°s ‚Üí ese mensaje incluido
2. Query nueva sin relaci√≥n ‚Üí solo √∫ltimos 2-3 mensajes
3. Comparaci√≥n larga ‚Üí mensajes de comparaci√≥n previa incluidos

**M√©tricas a a√±adir:**
- Promedio de mensajes seleccionados por query
- Tokens ahorrados vs. selecci√≥n "dumb" (√∫ltimos N)
- Precisi√≥n de la selecci√≥n (manual review)

**Estimaci√≥n:** 1.5 horas

---

### **Entregables Fase 4**
- [ ] SmartContextManager implementado
- [ ] Integrado en endpoint de streaming
- [ ] Selecci√≥n inteligente funcionando
- [ ] M√©tricas de uso de contexto implementadas
- [ ] Ahorro de tokens documentado

---

## **FASE 5: Tooling & Observability (DEBUGGING) - 3-4 horas**

### Objetivo
Herramientas para debugging y observaci√≥n del sistema de contexto

### Tareas

#### ‚úÖ **Tarea 5.1: Debug Endpoint**

**Archivo:** `backend/app/api/routes_sessions.py`

```python
@router.get("/{session_id}/context-debug")
async def debug_conversation_context(
    session_id: str,
    mode: Mode = Query(default=settings.default_mode)
):
    """
    Endpoint para visualizar el estado del contexto conversacional.
    
    √ötil para:
    - Ver qu√© mensajes est√°n en la ventana de contexto
    - Debugging de resoluci√≥n de referencias
    - An√°lisis de relevancia de mensajes
    """
    mgr = get_session_manager(mode)
    full_history = mgr.get_conversation_history(session_id, limit=50)
    
    # Si hay un SmartContextManager, simular selecci√≥n
    from app.services.smart_context_manager import SmartContextManager
    context_mgr = SmartContextManager()
    
    # Analizar cada mensaje
    analyzed_messages = []
    for i, msg in enumerate(full_history):
        analyzed_messages.append({
            "index": i,
            "role": msg.role if hasattr(msg, 'role') else msg.get('role'),
            "content_preview": msg.content[:100] if hasattr(msg, 'content') else msg.get('content', '')[:100],
            "timestamp": msg.timestamp if hasattr(msg, 'timestamp') else msg.get('timestamp'),
            "in_default_window": i >= len(full_history) - 6,
            "tokens_estimated": len(msg.content.split()) * 1.3 if hasattr(msg, 'content') else 0
        })
    
    return {
        "session_id": session_id,
        "total_messages": len(full_history),
        "default_context_window": 6,
        "messages": analyzed_messages,
        "context_status": {
            "has_recent_context": len(full_history) > 0,
            "context_window_full": len(full_history) >= 6,
            "total_tokens_in_window": sum(m["tokens_estimated"] for m in analyzed_messages[-6:])
        }
    }
```

**Estimaci√≥n:** 1.5 horas

---

#### ‚úÖ **Tarea 5.2: Enhanced Logging**

**Archivo:** `backend/app/utils/debug_logger.py`

```python
def log_context_resolution(
    original_query: str,
    resolved_query: str,
    referenced_entities: list[str],
    confidence: float,
    conversation_history: list[dict]
):
    """Log completo de resoluci√≥n de contexto."""
    
def log_context_selection(
    current_query: str,
    full_history_count: int,
    selected_count: int,
    selection_reason: str,
    relevance_scores: dict
):
    """Log de selecci√≥n inteligente de contexto."""
```

**Estimaci√≥n:** 1 hora

---

#### ‚úÖ **Tarea 5.3: Frontend Context Indicator (Opcional)**

**Archivo:** `frontend/src/components/chat/MessageInput.jsx`

A√±adir indicador visual cuando hay contexto activo:

```jsx
{conversationHistory.length > 0 && (
  <div className="context-indicator">
    üí¨ {conversationHistory.length} messages in context
  </div>
)}
```

**Estimaci√≥n:** 1 hora (opcional)

---

### **Entregables Fase 5**
- [ ] Debug endpoint funcionando
- [ ] Logging mejorado con detalles de contexto
- [ ] Documentaci√≥n de endpoints de debugging
- [ ] (Opcional) Indicador visual en frontend

---

# PARTE 4: TESTING & VALIDATION

## 4.1 Test Suite Completo

### **Test Suite 1: Flujo B√°sico**
```python
def test_context_flows_through_pipeline():
    """Contexto fluye de endpoint ‚Üí RAG ‚Üí Orchestrator ‚Üí Structure"""
    
def test_context_preserved_in_structures():
    """Structures reciben conversation_history intacto"""
```

### **Test Suite 2: Context Resolution**
```python
def test_pronoun_resolution():
    """'√©l' se resuelve a nombre del candidato"""
    
def test_multiple_entity_resolution():
    """'estos dos' se resuelve a nombres correctos"""
    
def test_no_context_fallback():
    """Sin contexto, funciona normalmente"""
```

### **Test Suite 3: Context-Aware Behavior**
```python
def test_risk_assessment_adapts_to_concerns():
    """RiskAssessment prioriza seg√∫n preocupaciones previas"""
    
def test_comparison_maintains_criteria():
    """ComparisonStructure mantiene criterios entre queries"""
```

### **Test Suite 4: Smart Context**
```python
def test_relevant_message_selection():
    """SmartContextManager selecciona mensajes relevantes"""
    
def test_token_limit_respected():
    """No excede l√≠mite de tokens configurado"""
```

**Estimaci√≥n Total Testing:** 4-5 horas

---

## 4.2 Casos de Uso Reales

### **Caso 1: An√°lisis iterativo de candidato**
```
Usuario: "Dame el perfil de Juan P√©rez"
‚Üí SingleCandidateStructure

Usuario: "¬øQu√© red flags tiene?"
‚Üí RiskAssessmentStructure con context
‚Üí ‚úÖ Sabe que es Juan P√©rez

Usuario: "¬øC√≥mo se compara con Mar√≠a Garc√≠a?"
‚Üí ComparisonStructure con context
‚Üí ‚úÖ Sabe que comparar Juan vs Mar√≠a
```

### **Caso 2: B√∫squeda y refinamiento**
```
Usuario: "Busca desarrolladores Frontend"
‚Üí SearchStructure

Usuario: "¬øCu√°l tiene m√°s experiencia con React?"
‚Üí SearchStructure con context
‚Üí ‚úÖ Sabe que filtrar dentro de resultados previos
```

### **Caso 3: Comparaciones iterativas**
```
Usuario: "Compara Juan y Mar√≠a para Backend"
‚Üí ComparisonStructure con criterio "Backend"

Usuario: "¬øY para Frontend?"
‚Üí ComparisonStructure con context
‚Üí ‚úÖ Mantiene candidatos, cambia criterio
```

---

# PARTE 5: M√âTRICAS Y MONITOREO

## 5.1 M√©tricas a Implementar

### **Context Usage Metrics**
```python
{
  "context_usage": {
    "queries_with_context": 156,
    "queries_without_context": 23,
    "avg_messages_in_context": 4.2,
    "avg_context_tokens": 847,
    "context_resolution_rate": 0.73  # % queries con referencias resueltas
  }
}
```

### **Resolution Metrics**
```python
{
  "resolution_metrics": {
    "references_detected": 89,
    "references_resolved": 81,
    "avg_confidence": 0.87,
    "low_confidence_count": 8  # confidence < 0.5
  }
}
```

### **Performance Metrics**
```python
{
  "performance": {
    "context_resolution_ms": 45,
    "context_selection_ms": 23,
    "total_overhead_ms": 68
  }
}
```

---

# PARTE 6: CRONOGRAMA Y RECURSOS

## 6.1 Estimaci√≥n Total

| Fase | Tiempo | Prioridad | Dependencias |
|------|--------|-----------|--------------|
| Fase 1: Core Integration | 6-8 horas | üî¥ CR√çTICO | Ninguna |
| Fase 2: Context Resolution | 8-10 horas | üü† ALTO | Fase 1 |
| Fase 3: Context-Aware Structures | 5-6 horas | üü° MEDIO | Fase 1, 2 |
| Fase 4: Smart Context | 4-5 horas | üü¢ BAJO | Fase 1 |
| Fase 5: Tooling | 3-4 horas | üü¢ BAJO | Ninguna (paralelo) |
| Testing | 4-5 horas | üî¥ CR√çTICO | Todas |

**Total:** 30-38 horas

---

## 6.2 Cronograma Recomendado

### **Sprint 1 (1 semana):** Foundation
- D√≠a 1-2: Fase 1 (Core Integration)
- D√≠a 3-4: Fase 2 (Context Resolution)
- D√≠a 5: Testing Fase 1 y 2

### **Sprint 2 (1 semana):** Enhancement
- D√≠a 1-2: Fase 3 (Context-Aware Structures)
- D√≠a 3: Fase 4 (Smart Context)
- D√≠a 4-5: Fase 5 (Tooling) + Testing final

---

## 6.3 Rollout Plan

### **Stage 1: Internal Testing**
- Activar en modo local solamente
- Testing manual exhaustivo
- Recolecci√≥n de m√©tricas

### **Stage 2: Beta**
- Feature flag: `ENABLE_SMART_CONTEXT`
- Activar para 20% de queries
- Comparar con baseline (sin contexto)

### **Stage 3: Full Rollout**
- Si m√©tricas positivas ‚Üí 100%
- Monitoreo continuo
- Ajustes seg√∫n feedback

---

# PARTE 7: RIESGOS Y MITIGACI√ìN

## 7.1 Riesgos Identificados

### **Riesgo 1: Context Resolution Incorrecta**
**Impacto:** ALTO - Query mal resuelta ‚Üí respuesta incorrecta

**Mitigaci√≥n:**
- Threshold de confidence (min 0.7)
- Fallback a query original si confidence baja
- Logging exhaustivo para debugging

---

### **Riesgo 2: Token Budget Overflow**
**Impacto:** MEDIO - Contexto muy largo ‚Üí costos altos / errors

**Mitigaci√≥n:**
- Hard limit de tokens (2000)
- Smart context selection para optimizar
- Monitoring de token usage

---

### **Riesgo 3: Breaking Changes en Structures**
**Impacto:** ALTO - 9 estructuras a modificar

**Mitigaci√≥n:**
- Cambios backward-compatible (par√°metro opcional)
- Tests para cada estructura antes/despu√©s
- Rollout gradual

---

### **Riesgo 4: Performance Degradation**
**Impacto:** MEDIO - Context resolution a√±ade latencia

**Mitigaci√≥n:**
- Async processing donde posible
- Caching de entity extraction
- Target: <100ms overhead m√°ximo

---

# PARTE 8: CRITERIOS DE √âXITO

## 8.1 M√©tricas de √âxito

### **Funcionalidad**
- [ ] ‚úÖ 100% de queries con contexto fluyen correctamente
- [ ] ‚úÖ Referencias resueltas con >85% accuracy
- [ ] ‚úÖ 0 breaking changes en funcionalidad existente

### **Performance**
- [ ] ‚úÖ Overhead de contexto <100ms por query
- [ ] ‚úÖ Uso de tokens optimizado (ahorro >30% vs baseline)

### **User Experience**
- [ ] ‚úÖ Usuarios pueden hacer seguimiento de queries sin repetir contexto
- [ ] ‚úÖ Respuestas mantienen coherencia conversacional
- [ ] ‚úÖ 0 casos donde contexto cause confusi√≥n

### **Code Quality**
- [ ] ‚úÖ 90%+ test coverage en nuevos componentes
- [ ] ‚úÖ Logging completo para debugging
- [ ] ‚úÖ Documentaci√≥n actualizada

---

# PARTE 9: DOCUMENTACI√ìN

## 9.1 Documentos a Crear/Actualizar

### **Nuevos Documentos**
1. `docs/CONTEXT_RESOLUTION_GUIDE.md` - C√≥mo funciona la resoluci√≥n
2. `docs/SMART_CONTEXT_ALGORITHM.md` - Algoritmo de selecci√≥n
3. `docs/CONTEXT_DEBUGGING.md` - Gu√≠a de debugging

### **Documentos a Actualizar**
1. `docs/CONVERSATIONAL_CONTEXT.md` - A√±adir nueva arquitectura
2. `docs/ARCHITECTURE_MODULES.md` - A√±adir ContextResolver
3. `README.md` - Mencionar capacidad de contexto

---

# CONCLUSI√ìN

Este plan integra completamente el sistema de contexto conversacional con la arquitectura STRUCTURES/MODULES/ORCHESTRATOR, resolviendo la desconexi√≥n actual y habilitando verdaderas conversaciones iterativas context-aware.

**Pr√≥ximo paso:** Comenzar con Fase 1 (Core Integration) para establecer la base.
